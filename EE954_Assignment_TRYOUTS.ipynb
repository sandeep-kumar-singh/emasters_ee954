{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeep-kumar-singh/emasters_ee954/blob/main/EE954_Assignment_TRYOUTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "1. Download the Fashion_MNIST dataset. You can find it on the official Fashion-MNIST website or by using PyTorch's torchvision.datasets module. Split the dataset into training, validation and testing sets. A common split is 80% of the data to train, 10% to validate, and 10% to test scenarios, but you can adjust this as needed. Normalize the images. This involves scaling the pixel values to a range between 0 and 1.\n",
        "\n",
        "2. Implement a MLP for classification. (total 40 marks)\n",
        "    <ol type=\"a\">\n",
        "    <li>Flatten the images into a single dimensional vector before feeding it to the model. (1 marks)</li>\n",
        "    <li>Write a pre-processing module for all the images. (3 marks)</li>\n",
        "    <li>Write the Forward pass from scratch. Use of the inbuilt forward pass function will result in 0 marks for this sub-question. (8 marks)</li>\n",
        "    <li>Write the Backward pass from scratch. Use the inbuilt back propagation function will result in 0 marks for this sub-question (12 marks)</li>\n",
        "    <li>Write the module for cross entropy loss (1 marks)</li>\n",
        "    <li>Experiment with different hyperparameters like number of layers, dropout, objective function, etc. and settle with a combination which performs the best for the given problem. (15 Marks)</li>\n",
        "    </ol>\n",
        "\n",
        "3. Implement a [CNN backbone model](https://www.baeldung.com/cs/neural-network-backbone) using pytorch. (total 40 marks)\n",
        "    <ol type=\"a\">\n",
        "    <li>Build a small CNN model consisting of 5 convolution layers. Each convolution layer would be followed by a ReLU activation and a max pooling layer. (10 Marks )</li>\n",
        "    <li>Experiment with different kernel size, number of kernel each layer (keep number of filter same in each layer, double it in each layer etc) and settle with a combination which performs the best for the given problem. (10 Marks)</li>\n",
        "    <li>Try different weight initialization methods (random, Xavier, He) (5 Marks)</li>\n",
        "    <li>After extracting feature from CNN model use MLP for classification (use code from question 2) (15 Marks)</li>\n",
        "    </ol>\n",
        "\n",
        "4. Submit a report clearly explaining how you have built the models, the architecture of the models, learning rate, epochs used for training, evaluation metrics and the instructions for running the models. Compare the performance of the models on the different hyperparameters you tried and justify the observed behavior. (20 Marks)"
      ],
      "metadata": {
        "id": "1t2rodvUWl_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 - Data Preparation"
      ],
      "metadata": {
        "id": "46TXkkZUi1QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Import Dependencies\n",
        "# ==========================================================\n",
        "\n",
        "# for MLP\n",
        "import numpy as np\n",
        "\n",
        "# for Pytorch based backbone CNN\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "35tdT6raI6mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Data Preparation (using torch)\n",
        "# ==========================================================\n",
        "\n",
        "# PyTorch based flow to prepare and train a backbone CNN\n",
        "########################################################\n",
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),                                                       # this transform does the normalisation of data from [1,255] to [0.0, 1.0]\n",
        ")\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),                                                       # this transform does the normalisation of data from [1,255] to [0.0, 1.0]\n",
        ")\n",
        "\n",
        "# Split the training data into Training and Validation datasets\n",
        "training_data_subset_size = int(0.8 * len(training_data))\n",
        "validate_data_subset_size = len(training_data) - training_data_subset_size\n",
        "training_data_subset, validation_data_subset = random_split(training_data, [training_data_subset_size, validate_data_subset_size])\n",
        "\n",
        "# define batch-size to load data\n",
        "batch_size = 64\n",
        "# define num of epochs to be run for training\n",
        "epochs = 10\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data_subset, batch_size=batch_size)\n",
        "validate_dataloader = DataLoader(validation_data_subset, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pIm-vbVivZ8",
        "outputId": "44db7da5-6e61-4659-c62b-49f5f17ececb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Using downloaded and verified file: data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n",
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Using downloaded and verified file: data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Using downloaded and verified file: data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Using downloaded and verified file: data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Data Preparation (Alternate using numpy)\n",
        "# ==========================================================\n",
        "\n",
        "import os\n",
        "import gzip\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "\n",
        "# URL and data filename for the Fashion MNIST dataset\n",
        "DATASET_BASE_URL = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com'\n",
        "DATASET_BASE_FOLDER = './data/FashionMNIST/raw'\n",
        "DATA_FILENAME = {\n",
        "    'train_images': 'train-images-idx3-ubyte.gz',\n",
        "    'train_labels': 'train-labels-idx1-ubyte.gz',\n",
        "    'test_images': 't10k-images-idx3-ubyte.gz',\n",
        "    'test_labels': 't10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "# Helper function to download and extract the dataset\n",
        "def download_and_extract(filename, is_image=False):\n",
        "    if not os.path.exists('/'.join([DATASET_BASE_FOLDER, filename])):\n",
        "        os.makedirs(DATASET_BASE_FOLDER, exist_ok=True)\n",
        "        urllib.request.urlretrieve('/'.join([DATASET_BASE_URL, filename]),\n",
        "                                   '/'.join([DATASET_BASE_FOLDER, filename]))\n",
        "    filename = os.path.join(DATASET_BASE_FOLDER, filename)\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        if (is_image):\n",
        "            return np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28 * 28) / 255.0\n",
        "        else:\n",
        "            return np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "\n",
        "# Download and extract all files\n",
        "train_images__np = download_and_extract(DATA_FILENAME['train_images'], is_image=True)\n",
        "train_labels__np = download_and_extract(DATA_FILENAME['train_labels'])\n",
        "test_images__np = download_and_extract(DATA_FILENAME['test_images'], is_image=True)\n",
        "test_labels__np = download_and_extract(DATA_FILENAME['test_labels'])\n",
        "\n",
        "# Split the training set into training and validation sets\n",
        "num_train = int(0.8 * len(train_images__np))\n",
        "train_data__np, val_data__np = train_images__np[:num_train], train_images__np[num_train:]\n",
        "train_labels__np, val_labels__np = train_labels__np[:num_train], train_labels__np[num_train:]\n",
        "\n",
        "print(f'Training data shape   : Images - {train_data__np.shape} | Labels - {train_labels__np.shape}')\n",
        "print(f'Validation data shape : Images - {val_data__np.shape} | Labels - {val_labels__np.shape}')\n",
        "print(f'Test data shape       : Images - {test_images__np.shape} | Labels - {test_labels__np.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3p_jdbkjK8_",
        "outputId": "7d5d0695-6a2b-4add-f372-a1369f342526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape   : Images - (48000, 784) | Labels - (48000,)\n",
            "Validation data shape : Images - (12000, 784) | Labels - (12000,)\n",
            "Test data shape       : Images - (10000, 784) | Labels - (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Select Device for Execution\n",
        "# ==========================================================\n",
        "\n",
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n"
      ],
      "metadata": {
        "id": "G2D4-IAOWbVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4eebaf-37dd-4f59-b947-5c3541d5150d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Define MLP model for classification\n",
        "# ==========================================================\n",
        "\n",
        "# Define a class to represent dense layer\n",
        "class DenseLayer:\n",
        "    def __init__(self, input_dim, output_dim, activation, lambda_reg=0.1, reg_type=None):\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.weights = np.random.randn(input_dim, output_dim) * 0.01\n",
        "        self.biases =  np.zeros((1, output_dim))\n",
        "\n",
        "        self.activation_name = activation\n",
        "        self.lambda_reg = lambda_reg\n",
        "\n",
        "        self.output = None\n",
        "        self.input = None\n",
        "\n",
        "        self.reg_type = reg_type\n",
        "\n",
        "        if self.activation_name == 'relu':\n",
        "            self.activation = self.relu\n",
        "            self.activation_prime = self.relu_prime\n",
        "        elif self.activation_name == 'sigmoid':\n",
        "            self.activation = self.sigmoid\n",
        "            self.activation_prime = self.sigmoid_prime\n",
        "        elif self.activation_name == 'softmax':\n",
        "            self.activation = self.softmax\n",
        "            self.activation_prime = self.softmax_prime\n",
        "        else:\n",
        "            raise ValueError('activation function is not defined')\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"\"\"DenseLayer(input_dim:{self.input_dim}, output_dim:{self.output_dim}, activation:{self.activation_name})\"\"\"\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        self.input = input_data\n",
        "        #print(f\"self.input: {self.input.shape} \\n self.weights {self.weights.shape}\")\n",
        "        Z = np.dot(self.input, self.weights) + self.biases\n",
        "        #print(\"Z \", Z.shape)\n",
        "        self.output = self.activation(Z)\n",
        "        #print(f\"set..... self.output {self.output.shape}\")\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, dA, learning_rate, y=None):\n",
        "        \"\"\"\n",
        "        Backward propagate through this layer.\n",
        "        dA is the derivative of the loss with respect to the output of this layer.\n",
        "        y is the true labels, which is only needed if this is an output layer with softmax activation.\n",
        "        \"\"\"\n",
        "        #print(f\"self.output {self.output.shape}\")\n",
        "        if self.activation_name == 'softmax':\n",
        "            y_one_hot = np.zeros_like(self.output)\n",
        "            y_one_hot[np.arange(len(y)), y] = 1\n",
        "            # Calculate the derivative of the loss with respect to the softmax inputs\n",
        "            # print(len(y))\n",
        "            # print(self.output.shape)\n",
        "            dZ = (self.output - y_one_hot)\n",
        "            # print(f\"before : {dZ.shape}, {dZ}\")\n",
        "            # dZ = dZ / len(y)                                                    # why divide????\n",
        "            # print(f\"after : {dZ.shape}, {dZ}\")\n",
        "        else:\n",
        "            dZ = dA * self.activation_prime(self.output)\n",
        "\n",
        "        dA_prev = np.dot(dZ, self.weights.T)\n",
        "        dW = np.dot(self.input.T, dZ)\n",
        "        db = np.sum(dZ, axis=0, keepdims=True)\n",
        "\n",
        "        if self.reg_type:\n",
        "            if self.reg_type.upper() == \"L1\":\n",
        "                 #print(\"Using L1 regularization..\")\n",
        "                 weights_reg = self.lambda_reg * np.sign(self.weights)\n",
        "                 biases_reg = self.lambda_reg * np.sign(self.biases)\n",
        "            else:\n",
        "                 #print(\"Using L2 regularization....\")\n",
        "                 weights_reg = self.lambda_reg * self.weights\n",
        "                 biases_reg = self.lambda_reg * self.biases\n",
        "            self.weights -= learning_rate * (dW + weights_reg)\n",
        "            self.biases -= learning_rate * (db + biases_reg)\n",
        "        else:\n",
        "            #print(\"No regularization....\")\n",
        "            self.weights -= learning_rate * dW\n",
        "            self.biases -= learning_rate * db\n",
        "\n",
        "        return dA_prev\n",
        "\n",
        "    # ==== Activation functions and their derivatives ====\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def relu_prime(self, x):\n",
        "        return np.where(x > 0, 1, 0)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_prime(self, x):\n",
        "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
        "\n",
        "    # Ref https://stackoverflow.com/questions/40575841/numpy-calculate-the-derivative-of-the-softmax-function\n",
        "    def softmax(self,Z):\n",
        "        exp_scores = np.exp(Z)\n",
        "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)  # Softmax activation\n",
        "\n",
        "    # The derivative of the cross-entropy loss with respect to the input to the softmax is simply predictions - true_labels\n",
        "    def softmax_prime(self,x):\n",
        "        return None                 # NotImplemented because not used/required in current architecture\n",
        "\n",
        "\n",
        "# Define a class to represent MLP\n",
        "class MLP:\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.history = {'train_loss': [], 'val_loss': [], 'train_acc':[], 'val_acc':[]}\n",
        "\n",
        "    def add_layer(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for layer in self.layers:\n",
        "            X = layer.forward(X)\n",
        "        return X\n",
        "\n",
        "    def backward(self,output, learning_rate, y_train_batch):\n",
        "        i = 0\n",
        "        for layer in reversed(self.layers):\n",
        "\n",
        "            #print(layer)\n",
        "            # print(f\"{i}, =====================\")\n",
        "            i += 1\n",
        "            output = layer.backward(output, learning_rate, y_train_batch)\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward(X)\n",
        "        return np.argmax(output, axis=1)\n",
        "\n",
        "    def cross_entropy_loss(self,y, output):\n",
        "        m = y.shape[0]\n",
        "        log_likelihood = -np.log(output[range(m), y] + 1e-9)\n",
        "        loss = np.sum(log_likelihood) / m\n",
        "        return loss\n",
        "\n",
        "    def train(self, train_data, train_labels, val_data, val_labels, epochs=10, batch_size=64, learning_rate=0.01):\n",
        "        for epoch in range(epochs):\n",
        "            permutation = np.random.permutation(train_data.shape[0])\n",
        "            train_data = train_data[permutation]\n",
        "            train_labels = train_labels[permutation]\n",
        "            for i in range(0, train_data.shape[0], batch_size):\n",
        "                X_batch = train_data[i:i+batch_size]\n",
        "                y_batch = train_labels[i:i+batch_size]\n",
        "                output = self.forward(X_batch)\n",
        "                self.backward(output, learning_rate, y_batch)\n",
        "            train_loss = self.cross_entropy_loss(train_labels, self.forward(train_data))\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "\n",
        "            val_output = self.forward(val_data)\n",
        "            val_loss = self.cross_entropy_loss(val_labels, val_output)  # Use val_labels directly\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "\n",
        "            val_accuracy = np.mean(self.predict(val_data) == val_labels)\n",
        "            train_acc = np.mean(self.predict(train_data) == train_labels)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_acc'].append(val_accuracy)\n",
        "            print(f'Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "#####################################\n"
      ],
      "metadata": {
        "id": "9TOGxE8qYEYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the MLP architecture\n",
        "input_size = 28 * 28\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "\n",
        "# create the instance of MLP\n",
        "mlp = MLP()\n",
        "mlp.add_layer(DenseLayer(input_size, hidden_size, 'relu'))      #reg_type=\"L2\" does not help\n",
        "mlp.add_layer(DenseLayer(hidden_size, output_size, 'softmax'))  #reg_type=\"L2\" does not help\n",
        "\n",
        "epochs = 1\n",
        "learning_rate = 0.01\n",
        "print(\"Training the classigication MLP model\")\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    # mlp.train(train_data__np[0:5], train_labels__np[0:5], val_data__np[0:5], val_labels__np[0:5], batch_size=5)\n",
        "    mlp.train(train_data__np, train_labels__np, val_data__np, val_labels__np)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj4FWaiWmuHs",
        "outputId": "c982761e-ee9e-457e-960c-15ce4537baf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the classigication MLP model\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 1, Training Loss: 0.6765, Validation Loss: 0.6780, Validation Accuracy: 0.7585\n",
            "Epoch 2, Training Loss: 0.5844, Validation Loss: 0.6009, Validation Accuracy: 0.7562\n",
            "Epoch 3, Training Loss: 0.6446, Validation Loss: 0.6655, Validation Accuracy: 0.7374\n",
            "Epoch 4, Training Loss: 0.5159, Validation Loss: 0.5460, Validation Accuracy: 0.8048\n",
            "Epoch 5, Training Loss: 0.5236, Validation Loss: 0.5660, Validation Accuracy: 0.7933\n",
            "Epoch 6, Training Loss: 0.5538, Validation Loss: 0.5926, Validation Accuracy: 0.7741\n",
            "Epoch 7, Training Loss: 0.4077, Validation Loss: 0.4470, Validation Accuracy: 0.8438\n",
            "Epoch 8, Training Loss: 0.3694, Validation Loss: 0.4216, Validation Accuracy: 0.8446\n",
            "Epoch 9, Training Loss: 0.4415, Validation Loss: 0.4967, Validation Accuracy: 0.8032\n",
            "Epoch 10, Training Loss: 0.3417, Validation Loss: 0.4082, Validation Accuracy: 0.8523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "# For Debugging - CNN Layer Output Size\n",
        "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "\n",
        "# input = torch.randn(784, 3, 3)\n",
        "\n",
        "# # m = nn.Conv2d(392, 784, (2, 2), stride=(1, 1), padding=(1, 1))\n",
        "# m = nn.MaxPool2d((2, 2))\n",
        "# output = m(input)\n",
        "\n",
        "# print(input.size(), output.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W966wQ6JROgL",
        "outputId": "f87141f8-192c-4930-be78-3c716a6162ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([784, 3, 3]) torch.Size([784, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Define backbone CNN model for feature extraction\n",
        "# ==========================================================\n",
        "\n",
        "class BackboneNeuralNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Build a small CNN model consisting of 5 convolution layers. Each convolution\n",
        "    layer would be followed by a ReLU activation and a max pooling layer.\n",
        "\n",
        "    Dense network with 2 layers, with a ReLU activation after first layer. This\n",
        "    layer can be used ONLY when testing CNN model in isolation. After extracting\n",
        "    feature from CNN model, use MLP for classification.\n",
        "\n",
        "    NOTE: Dense network is not used, if `backbone_only` is `True`.\n",
        "\n",
        "    REFERENCES:\n",
        "        1. https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
        "        nn.Sequential()\n",
        "\n",
        "        2. https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
        "        nn.Conv2d(\n",
        "            in_channels = number of layers in input images. Grayscale or monochrome images have 1 in_channels\n",
        "            out_channels = number of channels in the output produced. This is a hyperparameter, which signifies the number of kernels\n",
        "            kernel_size = `(m,n)` for a kernel/filter dimension, or simply n for a square (n,n) kernel/filter dimension\n",
        "            stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None are other properties with default values\n",
        "        )\n",
        "\n",
        "        3. https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU\n",
        "        nn.ReLU()\n",
        "\n",
        "        4. https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d\n",
        "        nn.MaxPool2d(\n",
        "            kernel_size = `(m,n)` for a kernel/filter dimension, or simply n for a square (n,n) kernel/filter dimension\n",
        "            stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False are other properties with default values\n",
        "        )\n",
        "\n",
        "        5. https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
        "        nn.Linear(\n",
        "            in_features = size of each input sample\n",
        "            out_features = size of each output sample\n",
        "            bias=True, device=None, dtype=None are other properties with default values\n",
        "        )\n",
        "\n",
        "        6. https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax\n",
        "        nn.Softmax()\n",
        "\n",
        "        7. https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "        Training a Classifier\n",
        "    \"\"\"\n",
        "\n",
        "    # Constructor for the CNN Model.\n",
        "    #\n",
        "    # NOTE: If `backbone_only` is `True`, dense network is not used.\n",
        "    def __init__(self, backbone_only=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # this property helps the CNN transition from a full-fledged network to a backbone CNN\n",
        "        # the default value is False - meaning an object of this class can be used to predict the labels for Fashion-MNIST dataset\n",
        "        # if the value is set to True - an object of this class will return the flattened output from conv layers - thus acting as a backbone\n",
        "        self.backbone_only = backbone_only\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # CNN model consisting of 5 convolution layers with each convolution\n",
        "        # layer followed by a ReLU activation and a max pooling layer.\n",
        "        self.convolutional_relu_stack = nn.Sequential(\n",
        "            nn.Conv2d(1, 49, (3, 3), stride=(1, 1), padding=(1, 1)),    # input = (1,28,28), output = (49, 28, 28)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),                                       # input = (49, 28, 28), output = (49, 14, 14)\n",
        "            nn.Conv2d(49, 98, (2, 2), stride=(1, 1), padding=(1,1)),    # input = (49, 14, 14), output = (98, 15, 15)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),                                       # input = (98, 15, 15), output = (98, 7, 7)\n",
        "            nn.Conv2d(98, 196, (2, 2), stride=(1, 1), padding=(1,1)),   # input = (98, 7, 7), output = (196, 8, 8)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),                                       # input = (196, 8, 8), output = (196, 4, 4)\n",
        "            nn.Conv2d(196, 392, (2, 2), stride=(1, 1), padding=(1, 1)), # input = (196, 4, 4), output = (392, 5, 5)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),                                       # input = (392, 5, 5), output = (392, 2, 2)\n",
        "            nn.Conv2d(392, 784, (2, 2), stride=(1, 1), padding=(1, 1)), # input = (392, 2, 2), output = (784, 3, 3)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2))                                        # input = (784, 3, 3), output = (784,1,1)\n",
        "        )\n",
        "\n",
        "        # Dense network with 2 layers with a ReLU activation after first layer.\n",
        "        # This layer can be used ONLY when testing CNN model in isolation.\n",
        "        #\n",
        "        # NOTE: Dense network is not used, if `backbone_only` is `True`.\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(784, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    # Forward pass for CNN Model\n",
        "    def forward(self, x):\n",
        "        # print(f'CNN Input Size: {x.size()}')\n",
        "        x1 = self.convolutional_relu_stack(x)\n",
        "        # print(f'CNN Output Size: {x1.size()}')\n",
        "        x2 = self.flatten(x1)\n",
        "        # print(f'Flatten Size: {x2.size()}')\n",
        "\n",
        "        if self.backbone_only:  # return the flattened tensor containing feature extraction data\n",
        "            return x2\n",
        "\n",
        "        # default behaviour is to return the predicted labels\n",
        "        x3 = self.linear_relu_stack(x2)\n",
        "        return x3"
      ],
      "metadata": {
        "id": "mZBOeengJfSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create model instance\n",
        "model = BackboneNeuralNetwork().to(device)\n",
        "# print(model)\n",
        "\n",
        "# define loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "\n",
        "# forward pass implementation\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "# validation implementation\n",
        "def validate(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    validation_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            validation_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    validation_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Validation Phase: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {validation_loss:>8f} \\n\")\n",
        "\n",
        "# testing implementation\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Phase: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "# Train and Validate the CNN\n",
        "print(\"Training the backbone CNN model\")\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    validate(validate_dataloader, model, loss_fn)\n",
        "print(\"Done!\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch CNN backbone model state to model.pth\")\n",
        "\n",
        "# Load the model to perform testing on the trained variables\n",
        "model = BackboneNeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "# Test with the model\n",
        "test(test_dataloader, model, loss_fn)\n",
        "\n",
        "#####################################\n",
        "# Once the backbone model is prepared, trained, and tested,\n",
        "# start the integration of backbone model with custom MLP\n",
        "\n",
        "# define the MLP architecture\n",
        "input_size = 28 * 28\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "\n",
        "# create the instance of MLP\n",
        "mlp = MLP()\n",
        "mlp.add_layer(DenseLayer(input_size, hidden_size, 'relu'))      #reg_type=\"L2\" does not help\n",
        "mlp.add_layer(DenseLayer(hidden_size, output_size, 'softmax'))  #reg_type=\"L2\" does not help\n",
        "\n",
        "# train the MLP using features extracted from pre-trained backbone\n",
        "def feature_extraction(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    features = np.empty((size, 28*28), dtype=np.float64)\n",
        "    labels = np.empty((size), dtype=np.int64)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            features[(batch*batch_size):((batch+1)*batch_size)] = pred.numpy()  # extract the features in numpy arrays\n",
        "            labels[(batch*batch_size):((batch+1)*batch_size)] = y.numpy()       # extract the features in numpy arrays\n",
        "    return features, labels\n",
        "\n",
        "# create the instance of `backbone CNN model`\n",
        "backbone_model = BackboneNeuralNetwork(backbone_only=True).to(device)\n",
        "backbone_model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "# extract the features using backbone CNN\n",
        "classifier_train_data, classifier_train_labels = feature_extraction(train_dataloader, backbone_model)\n",
        "classifier_validation_data, classifier_validation_labels = feature_extraction(validate_dataloader, backbone_model)\n",
        "\n",
        "# let the MLP classify the data now based on feature-extracted dataset\n",
        "epochs = 1\n",
        "learning_rate = 0.01\n",
        "print(\"Training the classigication MLP model\")\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    mlp.train(classifier_train_data, classifier_train_labels, classifier_validation_data, classifier_validation_labels)\n"
      ],
      "metadata": {
        "id": "BnkLy-PyIvvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd17c605-e5b3-49bc-a78d-b355c250887a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([32, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([32, 784, 1, 1])\n",
            "Flatten Size: torch.Size([32, 784])\n",
            "Validation Phase: \n",
            " Accuracy: 84.5%, Avg loss: 0.410368 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.334472  [   64/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.390656  [ 6464/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.445933  [12864/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.384061  [19264/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.390573  [25664/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.400584  [32064/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.252892  [38464/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.341682  [44864/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([32, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([32, 784, 1, 1])\n",
            "Flatten Size: torch.Size([32, 784])\n",
            "Validation Phase: \n",
            " Accuracy: 86.0%, Avg loss: 0.367274 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.321534  [   64/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.371956  [ 6464/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.430022  [12864/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.326609  [19264/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.369561  [25664/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "loss: 0.390555  [32064/48000]\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n",
            "CNN Input Size: torch.Size([64, 1, 28, 28])\n",
            "CNN Output Size: torch.Size([64, 784, 1, 1])\n",
            "Flatten Size: torch.Size([64, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TO BE REMOVED"
      ],
      "metadata": {
        "id": "Ho0QgfOYIwGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./data ./data_bak"
      ],
      "metadata": {
        "id": "GHx8bxxf0f9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gzip\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "\n",
        "# URL and data filename for the Fashion MNIST dataset\n",
        "DATASET_BASE_URL = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com'\n",
        "DATASET_BASE_FOLDER = './data/FashionMNIST/raw'\n",
        "DATA_FILENAME = {\n",
        "    'train_images': 'train-images-idx3-ubyte.gz',\n",
        "    'train_labels': 'train-labels-idx1-ubyte.gz',\n",
        "    'test_images': 't10k-images-idx3-ubyte.gz',\n",
        "    'test_labels': 't10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "# Helper function to download and extract the dataset\n",
        "def download_and_extract(filename, is_image=False):\n",
        "    if not os.path.exists('/'.join([DATASET_BASE_FOLDER, filename])):\n",
        "        os.makedirs(DATASET_BASE_FOLDER, exist_ok=True)\n",
        "        urllib.request.urlretrieve('/'.join([DATASET_BASE_URL, filename]),\n",
        "                                   '/'.join([DATASET_BASE_FOLDER, filename]))\n",
        "    filename = os.path.join(DATASET_BASE_FOLDER, filename)\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        if (is_image):\n",
        "            return np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28 * 28) / 255.0\n",
        "        else:\n",
        "            return np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "\n",
        "# Download and extract all files\n",
        "train_images = download_and_extract(DATA_FILENAME['train_images'], is_image=True)\n",
        "train_labels = download_and_extract(DATA_FILENAME['train_labels'])\n",
        "test_images = download_and_extract(DATA_FILENAME['test_images'], is_image=True)\n",
        "test_labels = download_and_extract(DATA_FILENAME['test_labels'])\n",
        "\n",
        "# Split the training set into training and validation sets\n",
        "num_train = int(0.8 * len(train_images))\n",
        "train_data, val_data = train_images[:num_train], train_images[num_train:]\n",
        "train_labels, val_labels = train_labels[:num_train], train_labels[num_train:]\n",
        "\n",
        "print(f'Training data shape   : Images - {train_data.shape} | Labels - {train_labels.shape}')\n",
        "print(f'Validation data shape : Images - {val_data.shape} | Labels - {val_labels.shape}')\n",
        "print(f'Test data shape       : Images - {test_images.shape} | Labels - {test_labels.shape}')\n"
      ],
      "metadata": {
        "id": "FiDF748l5uQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6ca898-1032-47a4-f0c3-ed175638b832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape   : Images - (48000, 784) | Labels - (48000,)\n",
            "Validation data shape : Images - (12000, 784) | Labels - (12000,)\n",
            "Test data shape       : Images - (10000, 784) | Labels - (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 - MLP Implementation"
      ],
      "metadata": {
        "id": "H7wXZKfoiulb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
        "        self.b1 = np.zeros((1, hidden_size))\n",
        "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
        "        self.b2 = np.zeros((1, output_size))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.Z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.A1 = np.maximum(0, self.Z1)  # ReLU activation\n",
        "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
        "        exp_scores = np.exp(self.Z2)\n",
        "        self.A2 = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)  # Softmax activation\n",
        "        return self.A2\n",
        "\n",
        "    def backward(self, X, y, output, learning_rate=0.01):\n",
        "        m = y.shape[0]\n",
        "        grad_Z2 = output\n",
        "        grad_Z2[range(m), y] -= 1\n",
        "        grad_Z2 /= m\n",
        "\n",
        "        grad_W2 = np.dot(self.A1.T, grad_Z2)\n",
        "        grad_b2 = np.sum(grad_Z2, axis=0, keepdims=True)\n",
        "        grad_A1 = np.dot(grad_Z2, self.W2.T)\n",
        "        grad_Z1 = grad_A1 * (self.Z1 > 0)\n",
        "        grad_W1 = np.dot(X.T, grad_Z1)\n",
        "        grad_b1 = np.sum(grad_Z1, axis=0, keepdims=True)\n",
        "\n",
        "        self.W1 -= learning_rate * grad_W1\n",
        "        self.b1 -= learning_rate * grad_b1\n",
        "        self.W2 -= learning_rate * grad_W2\n",
        "        self.b2 -= learning_rate * grad_b2\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward(X)\n",
        "        return np.argmax(output, axis=1)\n",
        "\n",
        "# Loss function: Cross entropy loss\n",
        "def cross_entropy_loss(y, output):\n",
        "    m = y.shape[0]\n",
        "    print(f'm: {m}')\n",
        "    log_likelihood = -np.log(output[range(m), y] + 1e-9)\n",
        "    print(f'log likelihood: {log_likelihood.shape}')\n",
        "    loss = np.sum(log_likelihood) / m\n",
        "    return loss\n",
        "\n",
        "# def cross_entropy_loss(y, output):\n",
        "#     # Small constant to prevent log(0) error\n",
        "#     epsilon = 1e-9\n",
        "#     # Clip values to range to avoid log(0)\n",
        "#     #y_pred = np.clip(y_pred, epsilon, 1. - epsilon)\n",
        "#     # Calculate cross-entropy loss\n",
        "#     N = y.shape[0]\n",
        "#     print(f'y.shape: {y.shape} | output: {output[[range(N), y]]}')\n",
        "#     ce_loss = -np.sum(y * np.log(output[range(N), y] + epsilon)) / N\n",
        "#     return ce_loss\n",
        "\n",
        "# One-hot encode the labels\n",
        "def one_hot(y, num_classes):\n",
        "    return np.eye(num_classes)[y]\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels_one_hot = one_hot(train_labels, 10)\n",
        "val_labels_one_hot = one_hot(val_labels, 10)\n",
        "\n",
        "\n",
        "def train(model, train_data, train_labels, val_data, val_labels, epochs=10, batch_size=64, learning_rate=0.01):\n",
        "\n",
        "  training_losses = []\n",
        "  validation_losses = []\n",
        "  for epoch in range(epochs):\n",
        "    permutation = np.random.permutation(train_data.shape[0])\n",
        "    train_data = train_data[permutation]\n",
        "    train_labels = train_labels[permutation]\n",
        "\n",
        "    train_output = np.zeros_like(train_labels)\n",
        "    val_output = np.zeros_like(val_labels)\n",
        "\n",
        "    for i in range(0, train_data.shape[0], batch_size):\n",
        "      X_batch = train_data[i:i+batch_size]\n",
        "      y_batch = train_labels[i:i+batch_size]\n",
        "\n",
        "      train_output[i] = model.forward(X_batch)\n",
        "      model.backward(X_batch, y_batch, train_output[i], learning_rate)\n",
        "\n",
        "    train_loss = cross_entropy_loss(train_labels, train_output)\n",
        "    training_losses.append(train_loss)\n",
        "\n",
        "    val_output = model.forward(val_data)\n",
        "    val_loss = cross_entropy_loss(val_labels, val_output)  # Use val_labels directly\n",
        "    validation_losses.append(val_loss)\n",
        "\n",
        "    val_accuracy = np.mean(model.predict(val_data) == val_labels)\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "# Plot training vs validation loss\n",
        "  plt.plot(training_losses, label='Training Loss')\n",
        "  plt.plot(validation_losses, label='Validation Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 28 * 28\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "epochs = 20\n",
        "learning_rate = 0.01\n",
        "\n",
        "# def preprocess_images(images):\n",
        "#     return images.reshape(-1, 28 * 28) / 255.0\n",
        "\n",
        "# Instantiate and train the model\n",
        "model = MLP(input_size, hidden_size, output_size)\n",
        "train(model, train_data, train_labels, val_data, val_labels, epochs=epochs, learning_rate=learning_rate)\n",
        "\n",
        "# Test the model\n",
        "test_output = model.forward(test_images)\n",
        "test_accuracy = np.mean(model.predict(test_images) == test_labels)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Saving the model\n",
        "def save_model(model, filename):\n",
        "    np.savez(filename, W1=model.W1, b1=model.b1, W2=model.W2, b2=model.b2)\n",
        "\n",
        "save_model(model, 'mlp_model.npz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xa_UlIKNB4nD",
        "outputId": "7d4e777c-ec9c-426c-dd97-561981f40f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_labels: (48000,)\n",
            "train_output: (48000, 784)\n",
            "model.forward(X_batch): [[0.10030812 0.09921891 0.10064403 0.10012314 0.10062392 0.0990807\n",
            "  0.09855234 0.09853816 0.10122936 0.10168133]\n",
            " [0.1003623  0.09978658 0.09964169 0.09992482 0.100355   0.09986912\n",
            "  0.09955656 0.09967179 0.10003001 0.10080212]\n",
            " [0.10047218 0.09977374 0.0995427  0.10029408 0.10062794 0.09959224\n",
            "  0.09930976 0.099556   0.10024347 0.10058789]\n",
            " [0.10057461 0.10017877 0.10057387 0.09961079 0.10038848 0.09908568\n",
            "  0.0979472  0.09943483 0.10221432 0.09999146]\n",
            " [0.10094033 0.09972683 0.10063256 0.10021117 0.10117931 0.09849489\n",
            "  0.09849878 0.0986252  0.10158148 0.10010946]\n",
            " [0.10056716 0.10015183 0.09956531 0.09954895 0.10108571 0.09958902\n",
            "  0.09832613 0.09927663 0.10154627 0.10034299]\n",
            " [0.10051119 0.0996277  0.09975878 0.10024056 0.10085091 0.09896452\n",
            "  0.09953833 0.09933711 0.10110337 0.10006753]\n",
            " [0.10037    0.10029541 0.10002703 0.09994206 0.10032851 0.09978856\n",
            "  0.09923881 0.09970807 0.10062952 0.09967203]\n",
            " [0.10033732 0.10018667 0.10026887 0.09970134 0.10032523 0.09954994\n",
            "  0.09924155 0.09983553 0.10059816 0.09995539]\n",
            " [0.09983457 0.10000228 0.09952496 0.09992165 0.10015129 0.09968378\n",
            "  0.10008074 0.09997347 0.10031225 0.100515  ]\n",
            " [0.101095   0.09999428 0.09960565 0.09956699 0.10086248 0.0987292\n",
            "  0.09869226 0.10072399 0.10099976 0.09973039]\n",
            " [0.10133667 0.10005055 0.10026358 0.09908258 0.10049615 0.09938841\n",
            "  0.09866676 0.10079999 0.10017723 0.09973809]\n",
            " [0.10081712 0.0997505  0.10121246 0.09912189 0.10098305 0.09862808\n",
            "  0.09801881 0.10093326 0.101301   0.09923382]\n",
            " [0.10066873 0.0999488  0.10090916 0.09904656 0.1011304  0.09908339\n",
            "  0.09833471 0.10001763 0.10136746 0.09949317]\n",
            " [0.10062794 0.0998483  0.10028517 0.09966534 0.10139903 0.09880677\n",
            "  0.09853315 0.10098676 0.1007808  0.09906673]\n",
            " [0.10041501 0.10004116 0.10024604 0.09949691 0.10043903 0.09932724\n",
            "  0.09916135 0.10012686 0.1004607  0.10028569]\n",
            " [0.10074052 0.09939792 0.10062636 0.0994136  0.10117436 0.09912545\n",
            "  0.09868224 0.0994691  0.10124562 0.10012484]\n",
            " [0.10104491 0.09978523 0.1007365  0.10023955 0.10056329 0.09875786\n",
            "  0.09871325 0.09913878 0.10114904 0.0998716 ]\n",
            " [0.10012528 0.09974847 0.09998827 0.09968373 0.10031143 0.09975421\n",
            "  0.09942507 0.09970049 0.10054713 0.10071592]\n",
            " [0.10148    0.09963798 0.10029088 0.09981804 0.10138452 0.09827148\n",
            "  0.09877377 0.10061264 0.10109627 0.09863444]\n",
            " [0.10031579 0.10033552 0.09996356 0.09864685 0.10176346 0.0988705\n",
            "  0.09914181 0.10067343 0.1012273  0.09906179]\n",
            " [0.10043322 0.09933854 0.10064377 0.10044625 0.10077566 0.09919312\n",
            "  0.09890259 0.09981863 0.10036689 0.10008133]\n",
            " [0.10092764 0.10021577 0.10088751 0.09951034 0.10109225 0.09889216\n",
            "  0.0983044  0.100152   0.10096213 0.0990558 ]\n",
            " [0.10021643 0.09994248 0.09926496 0.09964518 0.10104094 0.09975144\n",
            "  0.09886047 0.09904695 0.10156147 0.10066967]\n",
            " [0.10089273 0.09999358 0.1005416  0.0991965  0.10094079 0.09920999\n",
            "  0.09845074 0.09887551 0.10109218 0.10080639]\n",
            " [0.10016773 0.10030026 0.10004704 0.09983017 0.10029516 0.0993807\n",
            "  0.09956409 0.09951933 0.10073269 0.10016284]\n",
            " [0.10133482 0.09974131 0.09995835 0.09931751 0.10148646 0.09940345\n",
            "  0.09800736 0.10048454 0.10074919 0.09951701]\n",
            " [0.1005713  0.09985933 0.10032466 0.09953195 0.1006675  0.09915304\n",
            "  0.09923321 0.10045495 0.10048642 0.09971763]\n",
            " [0.10047263 0.10029019 0.10024236 0.09933844 0.10058933 0.09956069\n",
            "  0.09850952 0.09986207 0.10106345 0.10007131]\n",
            " [0.10065518 0.09999032 0.09959638 0.09942458 0.10046328 0.09933292\n",
            "  0.0992615  0.100794   0.10040015 0.10008169]\n",
            " [0.09993659 0.09963459 0.09944567 0.10032737 0.10142288 0.0997847\n",
            "  0.09879815 0.09910586 0.10101978 0.10052441]\n",
            " [0.10019206 0.10005166 0.09961609 0.10017741 0.10026127 0.10001326\n",
            "  0.09906339 0.0994199  0.10008038 0.10112457]\n",
            " [0.0999211  0.09973306 0.0992167  0.0999819  0.10024544 0.09964924\n",
            "  0.0997932  0.09938686 0.10101774 0.10105476]\n",
            " [0.10023589 0.09949238 0.09902296 0.10015697 0.1008448  0.0997073\n",
            "  0.09936533 0.0996792  0.10056666 0.1009285 ]\n",
            " [0.10093878 0.09965579 0.10009526 0.09923871 0.10128183 0.09979157\n",
            "  0.09784585 0.09981681 0.10092382 0.10041158]\n",
            " [0.10074294 0.09987169 0.10038708 0.0993321  0.10159139 0.09867668\n",
            "  0.09929402 0.0993081  0.1011627  0.0996333 ]\n",
            " [0.09998797 0.10028864 0.09988778 0.10019363 0.10036454 0.10006772\n",
            "  0.0991908  0.09976042 0.09994552 0.10031298]\n",
            " [0.10022151 0.09950627 0.10046649 0.09998605 0.10055052 0.09967974\n",
            "  0.09922799 0.09849974 0.10071429 0.1011474 ]\n",
            " [0.10126153 0.09927855 0.09946394 0.1002261  0.10119636 0.09851071\n",
            "  0.0984999  0.10032753 0.10139927 0.09983612]\n",
            " [0.10089047 0.10026853 0.10067243 0.09985087 0.10105915 0.09841552\n",
            "  0.09882657 0.09953899 0.1010482  0.09942926]\n",
            " [0.10002819 0.09983606 0.0997938  0.09976223 0.10024056 0.10014232\n",
            "  0.09988912 0.09959013 0.10043762 0.10027995]\n",
            " [0.0998221  0.09980845 0.09937117 0.09950253 0.10103921 0.09988208\n",
            "  0.09946915 0.09990438 0.1005154  0.10068554]\n",
            " [0.09980457 0.10028487 0.0997064  0.09924004 0.10101673 0.09966695\n",
            "  0.09946319 0.09818836 0.10163612 0.10099277]\n",
            " [0.09995243 0.09969641 0.09981663 0.10037036 0.10026818 0.09974393\n",
            "  0.09983385 0.09975783 0.10005733 0.10050305]\n",
            " [0.09992777 0.10018752 0.09961892 0.09999201 0.10006469 0.10002114\n",
            "  0.09958864 0.09966794 0.10030737 0.10062399]\n",
            " [0.10049324 0.0999892  0.09934243 0.09899281 0.10090608 0.09996109\n",
            "  0.09906076 0.09850479 0.10122497 0.10152463]\n",
            " [0.10029927 0.09992914 0.09963334 0.09932665 0.09988621 0.1002001\n",
            "  0.09968888 0.09984231 0.10014204 0.10105205]\n",
            " [0.10057387 0.10016802 0.10029942 0.10004418 0.10013581 0.09936155\n",
            "  0.09897016 0.10026165 0.10072843 0.09945693]\n",
            " [0.1001025  0.09952399 0.0997582  0.09974682 0.10033083 0.09998802\n",
            "  0.09974658 0.09940559 0.10073537 0.1006621 ]\n",
            " [0.09978175 0.09995327 0.09938351 0.09994749 0.10087885 0.09969195\n",
            "  0.09926884 0.09923261 0.10147332 0.10038841]\n",
            " [0.10127494 0.09990148 0.10047497 0.09946285 0.10040846 0.09926015\n",
            "  0.09826686 0.10001396 0.10096349 0.09997283]\n",
            " [0.10002504 0.09951606 0.10037207 0.09968869 0.09991412 0.09911799\n",
            "  0.09960168 0.10065696 0.10085181 0.10025558]\n",
            " [0.10097164 0.10018154 0.09931512 0.09944929 0.10120956 0.0985952\n",
            "  0.09813019 0.10027546 0.10174859 0.10012342]\n",
            " [0.10091241 0.0994856  0.1005884  0.09954783 0.10139285 0.09856736\n",
            "  0.09846835 0.09994317 0.10114617 0.09994787]\n",
            " [0.09995051 0.10039592 0.09938926 0.09954686 0.10172746 0.09970368\n",
            "  0.09698527 0.09943611 0.10229608 0.10056885]\n",
            " [0.10129699 0.09960913 0.09971463 0.09898508 0.10133853 0.0994406\n",
            "  0.09735851 0.09996417 0.10148275 0.10080961]\n",
            " [0.10025458 0.09927024 0.09945035 0.09977592 0.10021977 0.09911567\n",
            "  0.10001405 0.09970521 0.10044332 0.10175089]\n",
            " [0.10049476 0.09991487 0.10068677 0.09978778 0.10021009 0.09907259\n",
            "  0.09936641 0.0994075  0.1004989  0.10056034]\n",
            " [0.10088324 0.0994924  0.1002007  0.10049047 0.10116544 0.09895569\n",
            "  0.09855434 0.09979354 0.10108161 0.09938258]\n",
            " [0.10087902 0.09973206 0.10040634 0.09948077 0.10124033 0.09876606\n",
            "  0.09807442 0.0997459  0.10160242 0.10007268]\n",
            " [0.10170563 0.10001156 0.09995815 0.09958317 0.10163555 0.09836172\n",
            "  0.09845205 0.1008139  0.10112897 0.09834929]\n",
            " [0.1011622  0.09970912 0.10075716 0.10004532 0.10152208 0.09872859\n",
            "  0.09782679 0.09907183 0.10129652 0.09988038]\n",
            " [0.09977151 0.09983548 0.09909436 0.10042273 0.10093839 0.09959832\n",
            "  0.0992756  0.09978401 0.10009947 0.10118012]\n",
            " [0.10051904 0.09966844 0.09951571 0.10006495 0.099826   0.09984946\n",
            "  0.0996722  0.10001454 0.09986848 0.10100117]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not broadcast input array from shape (64,10) into shape (784,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0be28483f7b9>\u001b[0m in \u001b[0;36m<cell line: 125>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# Instantiate and train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m# Test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-0be28483f7b9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, train_labels, val_data, val_labels, epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'model.forward(X_batch): {out}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m       \u001b[0mtrain_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (64,10) into shape (784,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz pydot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9KD9ebJHIKQ",
        "outputId": "886fe8f0-81d2-4345-9ee3-2ea387d1b4eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "loaded_model = np.load('mlp_model.npz')\n",
        "W1 = loaded_model['W1']\n",
        "b1 = loaded_model['b1']\n",
        "W2 = loaded_model['W2']\n",
        "b2 = loaded_model['b2']\n",
        "\n",
        "\n",
        "# Create a new instance of the MLP with the loaded weights and biases\n",
        "loaded_mlp = MLP(input_size, hidden_size, output_size)\n",
        "loaded_mlp.W1 = W1\n",
        "loaded_mlp.b1 = b1\n",
        "loaded_mlp.W2 = W2\n",
        "loaded_mlp.b2 = b2\n",
        "\n",
        "\n",
        "# Use the loaded model for inference\n",
        "test_output = loaded_mlp.forward(test_images)\n",
        "test_predictions = np.argmax(test_output, axis=1)\n",
        "test_accuracy = np.mean(test_predictions == test_labels)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA0cffF0A8v9",
        "outputId": "199eb051-ff61-47f6-92a4-f8ef6be94e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 84.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "import gzip\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Helper function to download and extract the dataset\n",
        "def download_and_extract(url, filename):\n",
        "    if not os.path.exists(filename):\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        return np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "\n",
        "# Helper function to download and extract labels\n",
        "def download_and_extract_labels(url, filename):\n",
        "    if not os.path.exists(filename):\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        return np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "\n",
        "# URLs for the Fashion MNIST dataset\n",
        "urls = {\n",
        "    'train_images': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
        "    'train_labels': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
        "    'test_images': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
        "    'test_labels': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "# Download and extract all files\n",
        "train_images = download_and_extract(urls['train_images'], 'train-images-idx3-ubyte.gz').reshape(-1, 28*28) / 255.0\n",
        "train_labels = download_and_extract_labels(urls['train_labels'], 'train-labels-idx1-ubyte.gz')\n",
        "test_images = download_and_extract(urls['test_images'], 't10k-images-idx3-ubyte.gz').reshape(-1, 28*28) / 255.0\n",
        "test_labels = download_and_extract_labels(urls['test_labels'], 't10k-labels-idx1-ubyte.gz')\n",
        "\n",
        "# Split the training set into training and validation sets\n",
        "num_train = int(0.8 * len(train_images))\n",
        "train_data, val_data = train_images[:num_train], train_images[num_train:]\n",
        "train_labels, val_labels = train_labels[:num_train], train_labels[num_train:]\n",
        "\n",
        "# Define the MLP model with more complexity and regularization\n",
        "class MLP:\n",
        "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.5, l2_reg=0.01):\n",
        "        self.W1 = np.random.randn(input_size, hidden_sizes[0]) * 0.01\n",
        "        self.b1 = np.zeros((1, hidden_sizes[0]))\n",
        "        self.W2 = np.random.randn(hidden_sizes[0], hidden_sizes[1]) * 0.01\n",
        "        self.b2 = np.zeros((1, hidden_sizes[1]))\n",
        "        self.W3 = np.random.randn(hidden_sizes[1], output_size) * 0.01\n",
        "        self.b3 = np.zeros((1, output_size))\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.l2_reg = l2_reg\n",
        "\n",
        "    def forward(self, X, training=True):\n",
        "        self.Z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.A1 = np.maximum(0, self.Z1)  # ReLU activation\n",
        "        if training:\n",
        "            self.U1 = (np.random.rand(*self.A1.shape) < (1 - self.dropout_rate)) / (1 - self.dropout_rate)\n",
        "            self.A1 *= self.U1  # Apply dropout during training\n",
        "\n",
        "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
        "        self.A2 = np.maximum(0, self.Z2)  # ReLU activation\n",
        "        if training:\n",
        "            self.U2 = (np.random.rand(*self.A2.shape) < (1 - self.dropout_rate)) / (1 - self.dropout_rate)\n",
        "            self.A2 *= self.U2  # Apply dropout during training\n",
        "\n",
        "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
        "        exp_scores = np.exp(self.Z3)\n",
        "        self.A3 = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)  # Softmax activation\n",
        "        return self.A3\n",
        "\n",
        "    def backward(self, X, y, output, learning_rate=0.01):\n",
        "        m = y.shape[0]\n",
        "        grad_Z3 = output\n",
        "        grad_Z3[range(m), y] -= 1\n",
        "        grad_Z3 /= m\n",
        "\n",
        "        grad_W3 = np.dot(self.A2.T, grad_Z3) + self.l2_reg * self.W3\n",
        "        grad_b3 = np.sum(grad_Z3, axis=0, keepdims=True)\n",
        "        grad_A2 = np.dot(grad_Z3, self.W3.T)\n",
        "        grad_Z2 = grad_A2 * (self.Z2 > 0)\n",
        "        grad_W2 = np.dot(self.A1.T, grad_Z2) + self.l2_reg * self.W2\n",
        "        grad_b2 = np.sum(grad_Z2, axis=0, keepdims=True)\n",
        "        grad_A1 = np.dot(grad_Z2, self.W2.T)\n",
        "        grad_Z1 = grad_A1 * (self.Z1 > 0)\n",
        "        grad_W1 = np.dot(X.T, grad_Z1) + self.l2_reg * self.W1\n",
        "        grad_b1 = np.sum(grad_Z1, axis=0, keepdims=True)\n",
        "\n",
        "        self.W1 -= learning_rate * grad_W1\n",
        "        self.b1 -= learning_rate * grad_b1\n",
        "        self.W2 -= learning_rate * grad_W2\n",
        "        self.b2 -= learning_rate * grad_b2\n",
        "        self.W3 -= learning_rate * grad_W3\n",
        "        self.b3 -= learning_rate * grad_b3\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward(X, training=False)\n",
        "        return np.argmax(output, axis=1)\n",
        "\n",
        "# Loss function: Cross entropy loss\n",
        "def cross_entropy_loss(y, output):\n",
        "    m = y.shape[0]\n",
        "    log_likelihood = -np.log(output[range(m), y] + 1e-9)\n",
        "    loss = np.sum(log_likelihood) / m\n",
        "    return loss\n",
        "\n",
        "# One-hot encode the labels\n",
        "def one_hot(y, num_classes):\n",
        "    return np.eye(num_classes)[y]\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels_one_hot = one_hot(train_labels, 10)\n",
        "val_labels_one_hot = one_hot(val_labels, 10)\n",
        "\n",
        "def train(model, train_data, train_labels, val_data, val_labels, epochs=10, batch_size=32, learning_rate=0.01):\n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "    for epoch in range(epochs):\n",
        "        permutation = np.random.permutation(train_data.shape[0])\n",
        "        train_data = train_data[permutation]\n",
        "        train_labels = train_labels[permutation]\n",
        "\n",
        "        for i in range(0, train_data.shape[0], batch_size):\n",
        "            X_batch = train_data[i:i+batch_size]\n",
        "            y_batch = train_labels[i:i+batch_size]\n",
        "\n",
        "            output = model.forward(X_batch)\n",
        "            model.backward(X_batch, y_batch, output, learning_rate)\n",
        "\n",
        "        train_loss = cross_entropy_loss(train_labels, model.forward(train_data, training=False))\n",
        "        training_losses.append(train_loss)\n",
        "\n",
        "        val_output = model.forward(val_data, training=False)\n",
        "        val_loss = cross_entropy_loss(val_labels, val_output)\n",
        "        validation_losses.append(val_loss)\n",
        "\n",
        "        val_accuracy = np.mean(model.predict(val_data) == val_labels)\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    # Plot training vs validation loss\n",
        "    plt.plot(training_losses, label='Training Loss')\n",
        "    plt.plot(validation_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 28 * 28\n",
        "hidden_sizes = [256, 128]\n",
        "output_size = 10\n",
        "epochs = 20\n",
        "learning_rate = 0.01\n",
        "dropout_rate = 0.5\n",
        "l2_reg = 0.01\n",
        "\n",
        "def preprocess_images(images):\n",
        "    return images.reshape(-1, 28 * 28) / 255.0\n",
        "\n",
        "# Instantiate and train the model\n",
        "model = MLP(input_size, hidden_sizes, output_size, dropout_rate, l2_reg)\n",
        "train(model, train_data, train_labels, val_data, val_labels, epochs=epochs, learning_rate=learning_rate)\n",
        "\n",
        "# Test the model\n",
        "test_output = model.forward(test_images, training=False)\n",
        "test_accuracy = np.mean(model.predict(test_images) == test_labels)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Saving the model\n",
        "def save_model(model, filename):\n",
        "    np.savez(filename, W1=model.W1, b1=model.b1, W2=model.W2, b2=model.b2, W3=model.W3, b3=model.b3)\n",
        "\n",
        "save_model(model, 'mlp_model_complex.npz')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "X-CQ62OjPvuI",
        "outputId": "252a8d09-7ca0-40bc-9bee-003d0402afbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.5644, Validation Loss: 1.5599, Validation Accuracy: 0.4216\n",
            "Epoch 2, Training Loss: 1.0399, Validation Loss: 1.0328, Validation Accuracy: 0.6084\n",
            "Epoch 3, Training Loss: 0.8782, Validation Loss: 0.8658, Validation Accuracy: 0.6698\n",
            "Epoch 4, Training Loss: 0.8213, Validation Loss: 0.8149, Validation Accuracy: 0.6929\n",
            "Epoch 5, Training Loss: 0.7882, Validation Loss: 0.7760, Validation Accuracy: 0.7018\n",
            "Epoch 6, Training Loss: 0.7220, Validation Loss: 0.7127, Validation Accuracy: 0.7483\n",
            "Epoch 7, Training Loss: 0.7151, Validation Loss: 0.7102, Validation Accuracy: 0.7283\n",
            "Epoch 8, Training Loss: 0.6748, Validation Loss: 0.6699, Validation Accuracy: 0.7612\n",
            "Epoch 9, Training Loss: 0.7635, Validation Loss: 0.7746, Validation Accuracy: 0.6902\n",
            "Epoch 10, Training Loss: 0.6492, Validation Loss: 0.6516, Validation Accuracy: 0.7626\n",
            "Epoch 11, Training Loss: 0.6486, Validation Loss: 0.6460, Validation Accuracy: 0.7448\n",
            "Epoch 12, Training Loss: 0.6237, Validation Loss: 0.6250, Validation Accuracy: 0.7762\n",
            "Epoch 13, Training Loss: 0.6289, Validation Loss: 0.6305, Validation Accuracy: 0.7748\n",
            "Epoch 14, Training Loss: 0.6077, Validation Loss: 0.6076, Validation Accuracy: 0.7818\n",
            "Epoch 15, Training Loss: 0.6287, Validation Loss: 0.6316, Validation Accuracy: 0.7729\n",
            "Epoch 16, Training Loss: 0.5961, Validation Loss: 0.5984, Validation Accuracy: 0.7863\n",
            "Epoch 17, Training Loss: 0.5975, Validation Loss: 0.5967, Validation Accuracy: 0.7770\n",
            "Epoch 18, Training Loss: 0.5972, Validation Loss: 0.6000, Validation Accuracy: 0.7706\n",
            "Epoch 19, Training Loss: 0.6417, Validation Loss: 0.6453, Validation Accuracy: 0.7392\n",
            "Epoch 20, Training Loss: 0.6367, Validation Loss: 0.6443, Validation Accuracy: 0.7365\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "loaded_model = np.load('mlp_model_complex.npz')\n",
        "W1 = loaded_model['W1']\n",
        "b1 = loaded_model['b1']\n",
        "W2 = loaded_model['W2']\n",
        "b2 = loaded_model['b2']\n",
        "W3 = loaded_model['W3']\n",
        "b3 = loaded_model['b3']\n",
        "\n",
        "# Create a new instance of the MLP with the loaded weights and biases\n",
        "loaded_mlp = MLP(input_size, hidden_sizes, output_size, dropout_rate, l2_reg)\n",
        "loaded_mlp.W1 = W1\n",
        "loaded_mlp.b1 = b1\n",
        "loaded_mlp.W2 = W2\n",
        "loaded_mlp.b2 = b2\n",
        "loaded_mlp.W3 = W3\n",
        "loaded_mlp.b3 = b3\n",
        "\n",
        "# Use the loaded model for inference\n",
        "test_output = loaded_mlp.forward(test_images, training=False)\n",
        "test_predictions = np.argmax(test_output, axis=1)\n",
        "test_accuracy = np.mean(test_predictions == test_labels)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "NkflNx_HWJZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840b27ca-62dc-4bf9-b798-2a117b8b76a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 73.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pydot\n",
        "from IPython.display import Image, display\n",
        "from graphviz import Digraph\n",
        "\n",
        "def plot_mlp(input_size, hidden_size, output_size):\n",
        "    dot = Digraph()\n",
        "\n",
        "    # Add input layer nodes\n",
        "    for i in range(1, input_size + 1):\n",
        "        dot.node(f'input_{i}', label='Input', shape='circle')\n",
        "\n",
        "    # Add hidden layer nodes\n",
        "    for j in range(hidden_size):\n",
        "        dot.node(f'hidden_{j}', label='Hidden', shape='circle')\n",
        "\n",
        "    # Add output layer nodes\n",
        "    for k in range(output_size):\n",
        "        dot.node(f'output_{k}', label='Output', shape='circle')\n",
        "\n",
        "    # Add edges\n",
        "    for i in range(1, input_size + 1):\n",
        "      for j in range(hidden_size):\n",
        "        dot.edge(f'input_{i}', f'hidden_{j}')\n",
        "\n",
        "    for j in range(hidden_size):\n",
        "      for k in range(output_size):\n",
        "        dot.edge(f'hidden_{j}', f'output_{k}')\n",
        "\n",
        "\n",
        "    # Display the graph\n",
        "    display(dot)\n",
        "\n",
        "# Define the size of each layer\n",
        "input_size = 28 * 28\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "\n",
        "# Plot the MLP model architecture\n",
        "plot_mlp(input_size, hidden_size, output_size)\n"
      ],
      "metadata": {
        "id": "C_DAVBklc6eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pydot\n",
        "from IPython.display import Image\n",
        "\n",
        "def plot_mlp(input_size, hidden_size, output_size):\n",
        "    dot = pydot.Dot(graph_type='digraph')\n",
        "\n",
        "    # Add nodes for the input layer\n",
        "    input_node = pydot.Node('Input Layer', label=f'Input Layer ({input_size})', shape='record')\n",
        "    dot.add_node(input_node)\n",
        "\n",
        "    # Add nodes for the hidden layer\n",
        "    hidden_node = pydot.Node('Hidden Layer', label=f'<f0> Hidden Layer ({hidden_size})|<f1> ReLU', shape='record')\n",
        "    dot.add_node(hidden_node)\n",
        "\n",
        "    # Add nodes for the output layer\n",
        "    output_node = pydot.Node('Output Layer', label=f'<f0> Output Layer ({output_size})|<f1> Softmax', shape='record')\n",
        "    dot.add_node(output_node)\n",
        "\n",
        "    # Add edges from input layer to hidden layer\n",
        "    dot.add_edge(pydot.Edge(input_node, hidden_node, label=str(input_size), arrowhead='open'))\n",
        "\n",
        "    # Add edges from hidden layer to output layer\n",
        "    dot.add_edge(pydot.Edge(hidden_node, output_node, headlabel=str(hidden_size), arrowhead='open'))\n",
        "\n",
        "    # Display the graph\n",
        "    image = Image(dot.create_png())\n",
        "    display(image)\n",
        "\n",
        "# Define the size of each layer\n",
        "input_size = 28 * 28\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "\n",
        "# Plot the MLP model architecture\n",
        "plot_mlp(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "-DzyI4DjZ7w6",
        "outputId": "aa4d724b-0319-49d0-e6af-1d853bf9222c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "import gzip\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm  # Install tqdm library if not installed: pip install tqdm\n",
        "\n",
        "# Helper function to download and extract the dataset\n",
        "def download_and_extract(url, filename):\n",
        "    if not os.path.exists(filename):\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        return np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "\n",
        "# Helper function to download and extract labels\n",
        "def download_and_extract_labels(url, filename):\n",
        "    if not os.path.exists(filename):\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        return np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "\n",
        "# URLs for the Fashion MNIST dataset\n",
        "urls = {\n",
        "    'train_images': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
        "    'train_labels': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
        "    'test_images': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
        "    'test_labels': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "# Download and extract all files\n",
        "train_images = download_and_extract(urls['train_images'], 'train-images-idx3-ubyte.gz').reshape(-1, 28*28) / 255.0\n",
        "train_labels = download_and_extract_labels(urls['train_labels'], 'train-labels-idx1-ubyte.gz')\n",
        "test_images = download_and_extract(urls['test_images'], 't10k-images-idx3-ubyte.gz').reshape(-1, 28*28) / 255.0\n",
        "test_labels = download_and_extract_labels(urls['test_labels'], 't10k-labels-idx1-ubyte.gz')\n",
        "\n",
        "# Split the training set into training and validation sets\n",
        "num_train = int(0.8 * len(train_images))\n",
        "train_data, val_data = train_images[:num_train], train_images[num_train:]\n",
        "train_labels, val_labels = train_labels[:num_train], train_labels[num_train:]\n",
        "\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.5, l2_reg=0.01):\n",
        "        self.W1 = np.random.randn(input_size, hidden_sizes[0]) * 0.01\n",
        "        self.b1 = np.zeros((1, hidden_sizes[0]))\n",
        "        self.W2 = np.random.randn(hidden_sizes[0], hidden_sizes[1]) * 0.01\n",
        "        self.b2 = np.zeros((1, hidden_sizes[1]))\n",
        "        self.W3 = np.random.randn(hidden_sizes[1], output_size) * 0.01\n",
        "        self.b3 = np.zeros((1, output_size))\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.l2_reg = l2_reg\n",
        "\n",
        "    def forward(self, X, training=True):\n",
        "        Z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.Z1 = Z1\n",
        "        A1 = np.maximum(0, Z1)  # ReLU activation\n",
        "        self.A1 = A1\n",
        "        if training:\n",
        "            U1 = np.random.rand(*A1.shape) < (1 - self.dropout_rate)\n",
        "            A1 *= U1 / (1 - self.dropout_rate)  # Apply dropout during training\n",
        "\n",
        "        Z2 = np.dot(A1, self.W2) + self.b2\n",
        "        self.Z2 = Z2\n",
        "        A2 = np.maximum(0, Z2)  # ReLU activation\n",
        "        self.A2 = A2\n",
        "        if training:\n",
        "            U2 = np.random.rand(*A2.shape) < (1 - self.dropout_rate)\n",
        "            A2 *= U2 / (1 - self.dropout_rate)  # Apply dropout during training\n",
        "\n",
        "        Z3 = np.dot(A2, self.W3) + self.b3\n",
        "        self.Z3 = Z3\n",
        "        exp_scores = np.exp(Z3 - np.max(Z3, axis=1, keepdims=True))\n",
        "        A3 = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)  # Softmax activation\n",
        "        self.A3 = A3\n",
        "        return A3\n",
        "\n",
        "    def backward(self, X, y, output, learning_rate=0.01):\n",
        "        m = y.shape[0]\n",
        "        grad_Z3 = output\n",
        "        grad_Z3[range(m), y] -= 1\n",
        "        grad_Z3 /= m\n",
        "\n",
        "        grad_W3 = np.dot(self.A2.T, grad_Z3) + self.l2_reg * self.W3\n",
        "        grad_b3 = np.sum(grad_Z3, axis=0, keepdims=True)\n",
        "        grad_A2 = np.dot(grad_Z3, self.W3.T)\n",
        "        grad_Z2 = grad_A2 * (self.Z2 > 0)\n",
        "        grad_W2 = np.dot(self.A1.T, grad_Z2) + self.l2_reg * self.W2\n",
        "        grad_b2 = np.sum(grad_Z2, axis=0, keepdims=True)\n",
        "        grad_A1 = np.dot(grad_Z2, self.W2.T)\n",
        "        grad_Z1 = grad_A1 * (self.Z1 > 0)\n",
        "        grad_W1 = np.dot(X.T, grad_Z1) + self.l2_reg * self.W1\n",
        "        grad_b1 = np.sum(grad_Z1, axis=0, keepdims=True)\n",
        "\n",
        "        self.W1 -= learning_rate * grad_W1\n",
        "        self.b1 -= learning_rate * grad_b1\n",
        "        self.W2 -= learning_rate * grad_W2\n",
        "        self.b2 -= learning_rate * grad_b2\n",
        "        self.W3 -= learning_rate * grad_W3\n",
        "        self.b3 -= learning_rate * grad_b3\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward(X, training=False)\n",
        "        return np.argmax(output, axis=1)\n",
        "\n",
        "# Loss function: Cross entropy loss\n",
        "def cross_entropy_loss(y, output):\n",
        "    m = y.shape[0]\n",
        "    print(m)\n",
        "    log_likelihood = -np.log(output[range(m), y] + 1e-9)\n",
        "    loss = np.sum(log_likelihood) / m\n",
        "    return loss\n",
        "\n",
        "# One-hot encode the labels\n",
        "def one_hot(y, num_classes):\n",
        "    return np.eye(num_classes)[y]\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels_one_hot = one_hot(train_labels, 10)\n",
        "val_labels_one_hot = one_hot(val_labels, 10)\n",
        "\n",
        "def train(model, train_data, train_labels, val_data, val_labels, epochs=10, batch_size=32, learning_rate=0.01):\n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "    n_batches = train_data.shape[0] // batch_size\n",
        "    for epoch in range(epochs):\n",
        "        permutation = np.random.permutation(train_data.shape[0])\n",
        "        train_data = train_data[permutation]\n",
        "        train_labels = train_labels[permutation]\n",
        "\n",
        "        epoch_loss = 0\n",
        "        for i in tqdm(range(0, train_data.shape[0], batch_size), total=n_batches, desc=f'Epoch {epoch+1}/{epochs}'):\n",
        "            X_batch = train_data[i:i+batch_size]\n",
        "            y_batch = train_labels[i:i+batch_size]\n",
        "\n",
        "            output = model.forward(X_batch)\n",
        "            model.backward(X_batch, y_batch, output, learning_rate)\n",
        "            epoch_loss += cross_entropy_loss(y_batch, output)\n",
        "\n",
        "        train_loss = epoch_loss / n_batches\n",
        "        training_losses.append(train_loss)\n",
        "\n",
        "        val_output = model.forward(val_data, training=False)\n",
        "        val_loss = cross_entropy_loss(val_labels, val_output)\n",
        "        validation_losses.append(val_loss)\n",
        "\n",
        "        val_accuracy = np.mean(model.predict(val_data) == val_labels)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    # Plot training vs validation loss\n",
        "    plt.plot(training_losses, label='Training Loss')\n",
        "    plt.plot(validation_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 28 * 28\n",
        "hidden_sizes = [256, 128]\n",
        "output_size = 10\n",
        "epochs = 20\n",
        "learning_rate = 0.01\n",
        "dropout_rate = 0.5\n",
        "l2_reg = 0.01\n",
        "\n",
        "def preprocess_images(images):\n",
        "    return images.reshape(-1, 28 * 28) / 255.0\n",
        "\n",
        "# Instantiate and train the model\n",
        "model = MLP(input_size, hidden_sizes, output_size, dropout_rate, l2_reg)\n",
        "train(model, train_data, train_labels, val_data, val_labels, epochs=epochs, learning_rate=learning_rate)\n",
        "\n",
        "# Test the model\n",
        "test_output = model.forward(test_images, training=False)\n",
        "test_accuracy = np.mean(model.predict(test_images) == test_labels)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Saving the model\n",
        "def save_model(model, filename):\n",
        "    np.savez(filename, W1=model.W1, b1=model.b1, W2=model.W2, b2=model.b2, W3=model.W3, b3=model.b3)\n",
        "\n",
        "save_model(model, 'mlp_model_complex_updated.npz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qx5u2ttJX5Nb",
        "outputId": "5f34321a-dd0c-4c6f-b654-fdee4c86b8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20:   0%|          | 0/1500 [00:00<?, ?it/s]<ipython-input-24-60c70d8a0cda>:108: RuntimeWarning: invalid value encountered in log\n",
            "  log_likelihood = -np.log(output[range(m), y] + 1e-9)\n",
            "Epoch 1/20: 100%|██████████| 1500/1500 [00:04<00:00, 307.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Training Loss: nan, Validation Loss: 1.6971, Validation Accuracy: 0.3284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|██████████| 1500/1500 [00:04<00:00, 335.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20, Training Loss: nan, Validation Loss: 1.1249, Validation Accuracy: 0.5673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|██████████| 1500/1500 [00:06<00:00, 248.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20, Training Loss: nan, Validation Loss: 0.8927, Validation Accuracy: 0.6474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|██████████| 1500/1500 [00:05<00:00, 284.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20, Training Loss: nan, Validation Loss: 0.8564, Validation Accuracy: 0.6909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|██████████| 1500/1500 [00:06<00:00, 238.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20, Training Loss: nan, Validation Loss: 0.8032, Validation Accuracy: 0.6506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|██████████| 1500/1500 [00:04<00:00, 340.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20, Training Loss: nan, Validation Loss: 0.7341, Validation Accuracy: 0.7173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|██████████| 1500/1500 [00:06<00:00, 239.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20, Training Loss: nan, Validation Loss: 0.7037, Validation Accuracy: 0.7253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|██████████| 1500/1500 [00:04<00:00, 342.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20, Training Loss: nan, Validation Loss: 0.6485, Validation Accuracy: 0.7513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|██████████| 1500/1500 [00:04<00:00, 332.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20, Training Loss: nan, Validation Loss: 0.7122, Validation Accuracy: 0.7298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|██████████| 1500/1500 [00:05<00:00, 260.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20, Training Loss: nan, Validation Loss: 0.6858, Validation Accuracy: 0.7402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|██████████| 1500/1500 [00:04<00:00, 332.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20, Training Loss: nan, Validation Loss: 0.6488, Validation Accuracy: 0.7641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|██████████| 1500/1500 [00:06<00:00, 228.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20, Training Loss: nan, Validation Loss: 0.6256, Validation Accuracy: 0.7694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|██████████| 1500/1500 [00:06<00:00, 220.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20, Training Loss: nan, Validation Loss: 0.6013, Validation Accuracy: 0.7790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|██████████| 1500/1500 [00:05<00:00, 255.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20, Training Loss: nan, Validation Loss: 0.6004, Validation Accuracy: 0.7838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|██████████| 1500/1500 [00:04<00:00, 336.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20, Training Loss: nan, Validation Loss: 0.6263, Validation Accuracy: 0.7728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|██████████| 1500/1500 [00:06<00:00, 241.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20, Training Loss: nan, Validation Loss: 0.7422, Validation Accuracy: 0.6920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|██████████| 1500/1500 [00:04<00:00, 332.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20, Training Loss: nan, Validation Loss: 0.6422, Validation Accuracy: 0.7647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|██████████| 1500/1500 [00:06<00:00, 245.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20, Training Loss: nan, Validation Loss: 0.5942, Validation Accuracy: 0.7878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|██████████| 1500/1500 [00:04<00:00, 328.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20, Training Loss: nan, Validation Loss: 0.6123, Validation Accuracy: 0.7791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|██████████| 1500/1500 [00:04<00:00, 322.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20, Training Loss: nan, Validation Loss: 0.5940, Validation Accuracy: 0.7912\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function: Cross entropy loss\n",
        "def cross_entropy_loss(y, output):\n",
        "    m = y.shape[0]\n",
        "    print(m)\n",
        "    log_likelihood = -np.log(output[range(m), y] + 1e-9)\n",
        "    loss = np.sum(log_likelihood) / m\n",
        "    return loss\n",
        "\n",
        "val_loss = cross_entropy_loss(val_labels, val_output)"
      ],
      "metadata": {
        "id": "G2OC0oCG8Grm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sigma class 1 - 10 , sigma prob (yi*log(pi))"
      ],
      "metadata": {
        "id": "dVbXPtqy7fT_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3 - CNN Implementation"
      ],
      "metadata": {
        "id": "ul__stuBivGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torchvision import datasets, transforms, utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Types of fashion items in the\n",
        "def image_label(label):\n",
        "    IMAGE_LABEL_MAP = {\n",
        "                 0: 'T-shirt/Top',\n",
        "                 1: 'Trouser',\n",
        "                 2: 'Pullover',\n",
        "                 3: 'Dress',\n",
        "                 4: 'Coat',\n",
        "                 5: 'Sandal',\n",
        "                 6: 'Shirt',\n",
        "                 7: 'Sneaker',\n",
        "                 8: 'Bag',\n",
        "                 9: 'Ankle Boot'\n",
        "                 }\n",
        "    input = (label.item() if type(label) == torch.Tensor else label)\n",
        "    return IMAGE_LABEL_MAP[input]\n",
        "\n",
        "\n",
        "train_dataset = datasets.FashionMNIST('./data', download=True,\n",
        "                    transform=transforms.Compose([transforms.ToTensor()]))\n",
        "test_dataset = datasets.FashionMNIST('./data', download=True, train=False,\n",
        "                    transform=transforms.Compose([transforms.ToTensor()]))\n"
      ],
      "metadata": {
        "id": "H6u4BJ05-cbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10)\n",
        "\n",
        "print(f'a.size(): {(next(iter(train_loader)))[0].size()}')\n",
        "print(f'len(train_set): {len(train_dataset)}')\n",
        "\n",
        "# image, label = next(iter(train_dataset))\n",
        "# plt.imshow(image.squeeze(), cmap='gray')\n",
        "# print(image_label(label))\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "train_images, train_labels = batch\n",
        "print(type(train_images), type(train_labels))\n",
        "print(train_images.shape, train_labels.shape)\n",
        "\n",
        "grid = utils.make_grid(train_images, nrow=10)\n",
        "\n",
        "plt.figure(figsize=(15, 20))\n",
        "plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "print('labels: ', end=' ')\n",
        "for i, label in enumerate(train_labels):\n",
        "    print(image_label(label), end=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "LbrPnSZ1xlTe",
        "outputId": "af9076a3-e914-4908-ee54-c042e7dddd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.size(): torch.Size([10, 1, 28, 28])\n",
            "len(train_set): 60000\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "torch.Size([10, 1, 28, 28]) torch.Size([10])\n",
            "labels:  Ankle Boot, T-shirt/Top, T-shirt/Top, Dress, T-shirt/Top, Pullover, Sneaker, Pullover, Sandal, Sandal, "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x2000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Use GPU, if available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.fc1 = nn.Linear(512 * 1 * 1, 128)  # Adjust the input dimension\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f'x.shape: {x.shape}')\n",
        "        print(f'x: {x}')\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = self.pool(self.relu(self.conv4(x)))\n",
        "        x = self.pool(self.relu(self.conv5(x)))\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Initialize CNN model weights\n",
        "model.apply(initialize_weights)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# this is where we are having issue in running this CNN\n",
        "# we need to reshape the input to a shape compatible to the entry point of our CNN\n",
        "\n",
        "train_dataset = []\n",
        "for i in range(len(train_data)):\n",
        "   train_dataset.append([train_data[i], train_labels[i]])\n",
        "val_dataset = []\n",
        "for i in range(len(val_data)):\n",
        "   val_dataset.append([val_data[i], val_labels[i]])\n",
        "test_dataset = []\n",
        "for i in range(len(test_images)):\n",
        "   test_dataset.append([test_images[i], test_labels[i]])\n",
        "\n",
        "# Load dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        print(f'images: {images}')\n",
        "        outputs = model(images.type(torch.FloatTensor))\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "# Testing the model\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f'Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "F1GFPHq0jal0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "a8f3eecb-d6c8-4013-c9d0-c88afff56e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
            "x.shape: torch.Size([64, 784])\n",
            "x: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 784]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5a3088def44d>\u001b[0m in \u001b[0;36m<cell line: 74>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'images: {images}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-5a3088def44d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'x.shape: {x.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'x: {x}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 784]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "train_data_reshaped = np.reshape(train_data, (48000, 1, 28, 28))\n",
        "val_data_reshaped = np.reshape(val_data, (12000, 1, 28, 28))\n",
        "test_images_reshaped = np.reshape(test_images, (10000, 1, 28, 28))\n",
        "train_dataset = []\n",
        "for i in range(len(train_data_reshaped)):\n",
        "    # train_dataset.append(torch.utils.data.TensorDataset(torch.tensor(train_data_reshaped[i]).to(device), torch.tensor(train_labels[i]).to(device)))\n",
        "    train_dataset.append([train_data_reshaped[i], train_labels[i]])\n",
        "val_dataset = []\n",
        "for i in range(len(val_data_reshaped)):\n",
        "   val_dataset.append([val_data_reshaped[i], val_labels[i]])\n",
        "test_dataset = []\n",
        "for i in range(len(test_images_reshaped)):\n",
        "   test_dataset.append([test_images_reshaped[i], test_labels[i]])\n",
        "\n",
        "# Load dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "for X, y in train_loader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break\n",
        "\n",
        "for X, y in val_loader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break\n",
        "\n",
        "for X, y in test_loader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09crHsxJB98I",
        "outputId": "a304943b-3da4-408c-c045-eba1e01628c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.uint8\n",
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.uint8\n",
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Use GPU, if available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 1, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(28*28, 128)  # Adjust the input dimension\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(f'x.shape: {x.shape}')\n",
        "        # print(f'x: {x}')\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        # x = self.pool(self.relu(self.conv3(x)))\n",
        "        # x = self.pool(self.relu(self.conv4(x)))\n",
        "        # x = self.pool(self.relu(self.conv5(x)))\n",
        "\n",
        "        # x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Initialize CNN model weights\n",
        "model.apply(initialize_weights)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# this is where we are having issue in running this CNN\n",
        "# we need to reshape the input to a shape compatible to the entry point of our CNN\n",
        "\n",
        "train_data_reshaped = np.reshape(train_data, (48000, 1, 28, 28))\n",
        "val_data_reshaped = np.reshape(val_data, (12000, 1, 28, 28))\n",
        "test_images_reshaped = np.reshape(test_images, (10000, 1, 28, 28))\n",
        "train_dataset = []\n",
        "for i in range(len(train_data_reshaped)):\n",
        "   train_dataset.append([train_data_reshaped[i], train_labels[i]])\n",
        "val_dataset = []\n",
        "for i in range(len(val_data_reshaped)):\n",
        "   val_dataset.append([val_data_reshaped[i], val_labels[i]])\n",
        "test_dataset = []\n",
        "for i in range(len(test_images_reshaped)):\n",
        "   test_dataset.append([test_images_reshaped[i], test_labels[i]])\n",
        "\n",
        "# Load dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        # print(f'images: {images}')\n",
        "        outputs = model(images.type(torch.FloatTensor))\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "# Testing the model\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f'Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "LYPyHpCLEALM",
        "outputId": "2b224ff9-0b0f-4116-9e89-542f8ad0d33b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.5180\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Input type (double) and bias type (float) should be the same",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3b39eb8326ed>\u001b[0m in \u001b[0;36m<cell line: 87>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-3b39eb8326ed>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# print(f'x.shape: {x.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# print(f'x: {x}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# x = self.pool(self.relu(self.conv3(x)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (double) and bias type (float) should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural network optimization**"
      ],
      "metadata": {
        "id": "0vNiGQKzNI5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class DenseLayer:\n",
        "    def __init__(self, input_dim, output_dim, activation, lambda_reg=0.1, reg_type=None):\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.weights = np.random.randn(input_dim, output_dim)* 0.01\n",
        "        self.biases =  np.zeros((1, output_dim))\n",
        "        self.activation_name =activation\n",
        "        self.lambda_reg = lambda_reg\n",
        "        self.output = None\n",
        "        self.input = None\n",
        "        self.reg_type = reg_type\n",
        "\n",
        "        if activation == 'relu':\n",
        "            self.activation = self.relu\n",
        "            self.activation_prime = self.relu_prime\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = self.sigmoid\n",
        "            self.activation_prime = self.sigmoid_prime\n",
        "        elif activation == 'softmax':\n",
        "            self.activation = self.softmax\n",
        "            self.activation_prime = self.softmax_prime\n",
        "        else:\n",
        "            raise ValueError('activation function is not defined')\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"\"\"DenseLayer(input_dim:{self.input_dim}, output_dim:{self.output_dim}, activation:{self.activation_name})\"\"\"\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        self.input = input_data\n",
        "        #print(f\"self.input: {self.input.shape} \\n self.weights {self.weights.shape}\")\n",
        "        Z = np.dot(self.input, self.weights) + self.biases\n",
        "        #print(\"Z \", Z.shape)\n",
        "        self.output = self.activation(Z)\n",
        "        #print(f\"set..... self.output {self.output.shape}\")\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, dA,learning_rate, y=None):\n",
        "        \"\"\"Backward propagate through this layer.\n",
        "        dA is the derivative of the loss with respect to the output of this layer.\n",
        "        y is the true labels, which is only needed if this is an output layer with softmax activation.\n",
        "        \"\"\"\n",
        "        #print(f\"self.output {self.output.shape}\")\n",
        "        if self.activation_name == 'softmax':\n",
        "            y_one_hot = np.zeros_like(self.output)\n",
        "            y_one_hot[np.arange(len(y)), y] = 1\n",
        "            # Calculate the derivative of the loss with respect to the softmax inputs\n",
        "            dZ = (self.output - y_one_hot) / len(y)\n",
        "        else:\n",
        "            dZ = dA * self.activation_prime(self.output)\n",
        "\n",
        "        dA_prev = np.dot(dZ, self.weights.T)\n",
        "        dW = np.dot(self.input.T, dZ)\n",
        "        db = np.sum(dZ, axis=0, keepdims=True)\n",
        "\n",
        "        if self.reg_type:\n",
        "            if self.reg_type.upper() == \"L1\":\n",
        "                 #print(\"Using L1 regularization..\")\n",
        "                 weights_reg = self.lambda_reg * np.sign(self.weights)\n",
        "                 biases_reg = self.lambda_reg * np.sign(self.biases)\n",
        "            else:\n",
        "                 #print(\"Using L2 regularization....\")\n",
        "                 weights_reg = self.lambda_reg * self.weights\n",
        "                 biases_reg = self.lambda_reg * self.biases\n",
        "            self.weights -= learning_rate * (dW + weights_reg)\n",
        "            self.biases -= learning_rate * (db + biases_reg)\n",
        "        else:\n",
        "            #print(\"No regularization....\")\n",
        "            self.weights -= learning_rate * dW\n",
        "            self.biases -= learning_rate * db\n",
        "\n",
        "        return dA_prev\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def relu_prime(self, x):\n",
        "        return np.where(x > 0, 1, 0)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_prime(self, x):\n",
        "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
        "\n",
        "    # Ref https://stackoverflow.com/questions/40575841/numpy-calculate-the-derivative-of-the-softmax-function\n",
        "    def softmax(self,Z):\n",
        "        exp_scores = np.exp(Z)\n",
        "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)  # Softmax activation\n",
        "\n",
        "       # The derivative of the cross-entropy loss with respect to the input to the softmax is simply predictions - true_labels\n",
        "    def softmax_prime(self,x):\n",
        "        return 1\n",
        "class NeuralNetwork:\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.history = {'train_loss': [], 'val_loss': [], 'train_acc':[], 'val_acc':[]}\n",
        "\n",
        "\n",
        "    def add_layer(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for layer in self.layers:\n",
        "            X = layer.forward(X)\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward(X)\n",
        "        return np.argmax(output, axis=1)\n",
        "\n",
        "    def cross_entropy_loss(self,y, output):\n",
        "        m = y.shape[0]\n",
        "        log_likelihood = -np.log(output[range(m), y] + 1e-9)\n",
        "        loss = np.sum(log_likelihood) / m\n",
        "        return loss\n",
        "\n",
        "    def train(self, train_data, train_labels, val_data, val_labels, epochs=10, batch_size=64, learning_rate=0.01):\n",
        "      for epoch in range(epochs):\n",
        "        permutation = np.random.permutation(train_data.shape[0])\n",
        "        train_data = train_data[permutation]\n",
        "        train_labels = train_labels[permutation]\n",
        "        for i in range(0, train_data.shape[0], batch_size):\n",
        "          X_batch = train_data[i:i+batch_size]\n",
        "          y_batch = train_labels[i:i+batch_size]\n",
        "          output = self.forward(X_batch)\n",
        "          self.backward(output, learning_rate, y_batch)\n",
        "        train_loss = self.cross_entropy_loss(train_labels, self.forward(train_data))\n",
        "        self.history['train_loss'].append(train_loss)\n",
        "\n",
        "        val_output = self.forward(val_data)\n",
        "        val_loss = self.cross_entropy_loss(val_labels, val_output)  # Use val_labels directly\n",
        "        self.history['val_loss'].append(val_loss)\n",
        "\n",
        "        val_accuracy = np.mean(self.predict(val_data) == val_labels)\n",
        "        train_acc = np.mean(self.predict(train_data) == train_labels)\n",
        "        self.history['train_acc'].append(train_acc)\n",
        "        self.history['val_acc'].append(val_accuracy)\n",
        "        print(f'Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    def backward(self,output, learning_rate, y_train_batch):\n",
        "        for layer in reversed(self.layers):\n",
        "            #print(layer)\n",
        "            output = layer.backward(output, learning_rate,y_train_batch)"
      ],
      "metadata": {
        "id": "gLppGt39LVN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gzip\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "\n",
        "# URL and data filename for the Fashion MNIST dataset\n",
        "DATASET_BASE_URL = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com'\n",
        "DATASET_BASE_FOLDER = './data/FashionMNIST/raw'\n",
        "DATA_FILENAME = {\n",
        "    'train_images': 'train-images-idx3-ubyte.gz',\n",
        "    'train_labels': 'train-labels-idx1-ubyte.gz',\n",
        "    'test_images': 't10k-images-idx3-ubyte.gz',\n",
        "    'test_labels': 't10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "def one_hot(y, num_classes):\n",
        "    return np.eye(num_classes)[y]\n",
        "\n",
        "# Helper function to download and extract the dataset\n",
        "def download_and_extract(filename, is_image=False):\n",
        "    if not os.path.exists('/'.join([DATASET_BASE_FOLDER, filename])):\n",
        "        os.makedirs(DATASET_BASE_FOLDER, exist_ok=True)\n",
        "        urllib.request.urlretrieve('/'.join([DATASET_BASE_URL, filename]),\n",
        "                                   '/'.join([DATASET_BASE_FOLDER, filename]))\n",
        "    filename = os.path.join(DATASET_BASE_FOLDER, filename)\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        if (is_image):\n",
        "            return np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28 * 28) / 255.0\n",
        "        else:\n",
        "            return np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "\n",
        "# Download and extract all files\n",
        "train_images = download_and_extract(DATA_FILENAME['train_images'], is_image=True)\n",
        "train_labels = download_and_extract(DATA_FILENAME['train_labels'])\n",
        "test_images = download_and_extract(DATA_FILENAME['test_images'], is_image=True)\n",
        "test_labels = download_and_extract(DATA_FILENAME['test_labels'])\n",
        "\n",
        "# Split the training set into training and validation sets\n",
        "num_train = int(0.8 * len(train_images))\n",
        "train_data, val_data = train_images[:num_train], train_images[num_train:]\n",
        "train_labels, val_labels = train_labels[:num_train], train_labels[num_train:]\n",
        "\n",
        "print(f'Training data shape   : Images - {train_data.shape} | Labels - {train_labels.shape}')\n",
        "print(f'Validation data shape : Images - {val_data.shape} | Labels - {val_labels.shape}')\n",
        "print(f'Test data shape       : Images - {test_images.shape} | Labels - {test_labels.shape}')\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels_one_hot = one_hot(train_labels, 10)\n",
        "val_labels_one_hot = one_hot(val_labels, 10)\n",
        "print(f\"train_labels_one_hot: {train_labels_one_hot.shape}, val_labels_one_hot {val_labels_one_hot.shape}  \")\n",
        "input_size = 28 * 28\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "epochs = 20\n",
        "learning_rate = 0.01\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxULGZSYL5du",
        "outputId": "52ca0fc3-6e18-4cc2-cb7f-aaeaac565909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape   : Images - (48000, 784) | Labels - (48000,)\n",
            "Validation data shape : Images - (12000, 784) | Labels - (12000,)\n",
            "Test data shape       : Images - (10000, 784) | Labels - (10000,)\n",
            "train_labels_one_hot: (48000, 10), val_labels_one_hot (12000, 10)  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hyperparameters\n",
        "input_size = 28 * 28\n",
        "hidden_size = 100\n",
        "output_size = 10\n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "nn = NeuralNetwork()\n",
        "\n",
        "nn.add_layer(DenseLayer(input_size, hidden_size, 'relu'))  #reg_type=\"L2\" does not help\n",
        "nn.add_layer(DenseLayer(hidden_size, hidden_size, 'relu'))  #reg_type=\"L2\" does not help and sigmoid does not help\n",
        "nn.add_layer(DenseLayer(hidden_size, output_size, 'softmax'))  #reg_type=\"L2\" does not help\n",
        "nn.train( train_data, train_labels, val_data, val_labels, epochs=epochs, learning_rate=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_lz81UDMEVs",
        "outputId": "9e9a1d0e-2d4d-41f1-d371-efc0994063cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 2.2995, Validation Loss: 2.2996, Validation Accuracy: 0.1901\n",
            "Epoch 2, Training Loss: 2.0874, Validation Loss: 2.0852, Validation Accuracy: 0.2384\n",
            "Epoch 3, Training Loss: 1.2145, Validation Loss: 1.2089, Validation Accuracy: 0.5294\n",
            "Epoch 4, Training Loss: 1.0090, Validation Loss: 0.9982, Validation Accuracy: 0.6085\n",
            "Epoch 5, Training Loss: 0.8678, Validation Loss: 0.8620, Validation Accuracy: 0.6877\n",
            "Epoch 6, Training Loss: 0.8156, Validation Loss: 0.8102, Validation Accuracy: 0.6803\n",
            "Epoch 7, Training Loss: 0.7648, Validation Loss: 0.7577, Validation Accuracy: 0.7330\n",
            "Epoch 8, Training Loss: 0.7274, Validation Loss: 0.7247, Validation Accuracy: 0.7472\n",
            "Epoch 9, Training Loss: 0.6707, Validation Loss: 0.6708, Validation Accuracy: 0.7652\n",
            "Epoch 10, Training Loss: 0.6239, Validation Loss: 0.6216, Validation Accuracy: 0.7762\n",
            "Epoch 11, Training Loss: 0.6006, Validation Loss: 0.6036, Validation Accuracy: 0.7901\n",
            "Epoch 12, Training Loss: 0.5660, Validation Loss: 0.5750, Validation Accuracy: 0.7996\n",
            "Epoch 13, Training Loss: 0.5568, Validation Loss: 0.5689, Validation Accuracy: 0.7967\n",
            "Epoch 14, Training Loss: 0.5408, Validation Loss: 0.5538, Validation Accuracy: 0.8013\n",
            "Epoch 15, Training Loss: 0.5398, Validation Loss: 0.5493, Validation Accuracy: 0.8077\n",
            "Epoch 16, Training Loss: 0.5129, Validation Loss: 0.5272, Validation Accuracy: 0.8126\n",
            "Epoch 17, Training Loss: 0.5143, Validation Loss: 0.5324, Validation Accuracy: 0.8159\n",
            "Epoch 18, Training Loss: 0.4936, Validation Loss: 0.5071, Validation Accuracy: 0.8208\n",
            "Epoch 19, Training Loss: 0.4824, Validation Loss: 0.4986, Validation Accuracy: 0.8249\n",
            "Epoch 20, Training Loss: 0.4745, Validation Loss: 0.4893, Validation Accuracy: 0.8273\n",
            "Epoch 21, Training Loss: 0.4710, Validation Loss: 0.4889, Validation Accuracy: 0.8251\n",
            "Epoch 22, Training Loss: 0.4915, Validation Loss: 0.5142, Validation Accuracy: 0.8084\n",
            "Epoch 23, Training Loss: 0.4486, Validation Loss: 0.4679, Validation Accuracy: 0.8376\n",
            "Epoch 24, Training Loss: 0.4466, Validation Loss: 0.4646, Validation Accuracy: 0.8373\n",
            "Epoch 25, Training Loss: 0.4441, Validation Loss: 0.4633, Validation Accuracy: 0.8336\n",
            "Epoch 26, Training Loss: 0.4321, Validation Loss: 0.4533, Validation Accuracy: 0.8373\n",
            "Epoch 27, Training Loss: 0.4198, Validation Loss: 0.4401, Validation Accuracy: 0.8450\n",
            "Epoch 28, Training Loss: 0.4243, Validation Loss: 0.4428, Validation Accuracy: 0.8431\n",
            "Epoch 29, Training Loss: 0.4115, Validation Loss: 0.4332, Validation Accuracy: 0.8478\n",
            "Epoch 30, Training Loss: 0.4055, Validation Loss: 0.4287, Validation Accuracy: 0.8479\n",
            "Epoch 31, Training Loss: 0.4035, Validation Loss: 0.4265, Validation Accuracy: 0.8512\n",
            "Epoch 32, Training Loss: 0.3991, Validation Loss: 0.4243, Validation Accuracy: 0.8519\n",
            "Epoch 33, Training Loss: 0.3947, Validation Loss: 0.4187, Validation Accuracy: 0.8545\n",
            "Epoch 34, Training Loss: 0.3842, Validation Loss: 0.4113, Validation Accuracy: 0.8588\n",
            "Epoch 35, Training Loss: 0.3876, Validation Loss: 0.4136, Validation Accuracy: 0.8534\n",
            "Epoch 36, Training Loss: 0.3727, Validation Loss: 0.4009, Validation Accuracy: 0.8609\n",
            "Epoch 37, Training Loss: 0.3704, Validation Loss: 0.3971, Validation Accuracy: 0.8578\n",
            "Epoch 38, Training Loss: 0.3697, Validation Loss: 0.3998, Validation Accuracy: 0.8579\n",
            "Epoch 39, Training Loss: 0.3609, Validation Loss: 0.3911, Validation Accuracy: 0.8621\n",
            "Epoch 40, Training Loss: 0.3708, Validation Loss: 0.4016, Validation Accuracy: 0.8584\n",
            "Epoch 41, Training Loss: 0.3516, Validation Loss: 0.3833, Validation Accuracy: 0.8640\n",
            "Epoch 42, Training Loss: 0.3471, Validation Loss: 0.3806, Validation Accuracy: 0.8657\n",
            "Epoch 43, Training Loss: 0.3601, Validation Loss: 0.3952, Validation Accuracy: 0.8626\n",
            "Epoch 44, Training Loss: 0.3465, Validation Loss: 0.3819, Validation Accuracy: 0.8662\n",
            "Epoch 45, Training Loss: 0.3503, Validation Loss: 0.3861, Validation Accuracy: 0.8662\n",
            "Epoch 46, Training Loss: 0.3358, Validation Loss: 0.3722, Validation Accuracy: 0.8717\n",
            "Epoch 47, Training Loss: 0.3363, Validation Loss: 0.3739, Validation Accuracy: 0.8675\n",
            "Epoch 48, Training Loss: 0.3331, Validation Loss: 0.3737, Validation Accuracy: 0.8682\n",
            "Epoch 49, Training Loss: 0.3228, Validation Loss: 0.3615, Validation Accuracy: 0.8742\n",
            "Epoch 50, Training Loss: 0.3416, Validation Loss: 0.3824, Validation Accuracy: 0.8661\n",
            "Epoch 51, Training Loss: 0.3180, Validation Loss: 0.3590, Validation Accuracy: 0.8744\n",
            "Epoch 52, Training Loss: 0.3222, Validation Loss: 0.3653, Validation Accuracy: 0.8723\n",
            "Epoch 53, Training Loss: 0.3218, Validation Loss: 0.3639, Validation Accuracy: 0.8711\n",
            "Epoch 54, Training Loss: 0.3188, Validation Loss: 0.3627, Validation Accuracy: 0.8700\n",
            "Epoch 55, Training Loss: 0.3128, Validation Loss: 0.3608, Validation Accuracy: 0.8732\n",
            "Epoch 56, Training Loss: 0.3108, Validation Loss: 0.3591, Validation Accuracy: 0.8745\n",
            "Epoch 57, Training Loss: 0.3212, Validation Loss: 0.3716, Validation Accuracy: 0.8698\n",
            "Epoch 58, Training Loss: 0.2979, Validation Loss: 0.3477, Validation Accuracy: 0.8778\n",
            "Epoch 59, Training Loss: 0.3095, Validation Loss: 0.3598, Validation Accuracy: 0.8740\n",
            "Epoch 60, Training Loss: 0.3027, Validation Loss: 0.3534, Validation Accuracy: 0.8768\n",
            "Epoch 61, Training Loss: 0.2995, Validation Loss: 0.3545, Validation Accuracy: 0.8760\n",
            "Epoch 62, Training Loss: 0.2884, Validation Loss: 0.3443, Validation Accuracy: 0.8780\n",
            "Epoch 63, Training Loss: 0.3019, Validation Loss: 0.3603, Validation Accuracy: 0.8752\n",
            "Epoch 64, Training Loss: 0.2865, Validation Loss: 0.3419, Validation Accuracy: 0.8792\n",
            "Epoch 65, Training Loss: 0.3189, Validation Loss: 0.3783, Validation Accuracy: 0.8690\n",
            "Epoch 66, Training Loss: 0.2976, Validation Loss: 0.3570, Validation Accuracy: 0.8733\n",
            "Epoch 67, Training Loss: 0.2935, Validation Loss: 0.3549, Validation Accuracy: 0.8761\n",
            "Epoch 68, Training Loss: 0.2774, Validation Loss: 0.3387, Validation Accuracy: 0.8813\n",
            "Epoch 69, Training Loss: 0.2810, Validation Loss: 0.3425, Validation Accuracy: 0.8789\n",
            "Epoch 70, Training Loss: 0.2743, Validation Loss: 0.3411, Validation Accuracy: 0.8795\n",
            "Epoch 71, Training Loss: 0.2912, Validation Loss: 0.3614, Validation Accuracy: 0.8718\n",
            "Epoch 72, Training Loss: 0.2854, Validation Loss: 0.3547, Validation Accuracy: 0.8775\n",
            "Epoch 73, Training Loss: 0.2712, Validation Loss: 0.3424, Validation Accuracy: 0.8802\n",
            "Epoch 74, Training Loss: 0.2787, Validation Loss: 0.3470, Validation Accuracy: 0.8793\n",
            "Epoch 75, Training Loss: 0.2811, Validation Loss: 0.3524, Validation Accuracy: 0.8765\n",
            "Epoch 76, Training Loss: 0.2622, Validation Loss: 0.3334, Validation Accuracy: 0.8835\n",
            "Epoch 77, Training Loss: 0.2647, Validation Loss: 0.3391, Validation Accuracy: 0.8805\n",
            "Epoch 78, Training Loss: 0.2644, Validation Loss: 0.3387, Validation Accuracy: 0.8818\n",
            "Epoch 79, Training Loss: 0.2576, Validation Loss: 0.3338, Validation Accuracy: 0.8820\n",
            "Epoch 80, Training Loss: 0.2515, Validation Loss: 0.3290, Validation Accuracy: 0.8845\n",
            "Epoch 81, Training Loss: 0.2581, Validation Loss: 0.3383, Validation Accuracy: 0.8816\n",
            "Epoch 82, Training Loss: 0.2585, Validation Loss: 0.3415, Validation Accuracy: 0.8802\n",
            "Epoch 83, Training Loss: 0.2474, Validation Loss: 0.3299, Validation Accuracy: 0.8838\n",
            "Epoch 84, Training Loss: 0.2466, Validation Loss: 0.3301, Validation Accuracy: 0.8832\n",
            "Epoch 85, Training Loss: 0.2458, Validation Loss: 0.3292, Validation Accuracy: 0.8838\n",
            "Epoch 86, Training Loss: 0.2527, Validation Loss: 0.3395, Validation Accuracy: 0.8791\n",
            "Epoch 87, Training Loss: 0.2464, Validation Loss: 0.3355, Validation Accuracy: 0.8815\n",
            "Epoch 88, Training Loss: 0.2617, Validation Loss: 0.3491, Validation Accuracy: 0.8792\n",
            "Epoch 89, Training Loss: 0.2371, Validation Loss: 0.3292, Validation Accuracy: 0.8841\n",
            "Epoch 90, Training Loss: 0.2574, Validation Loss: 0.3486, Validation Accuracy: 0.8782\n",
            "Epoch 91, Training Loss: 0.2398, Validation Loss: 0.3301, Validation Accuracy: 0.8840\n",
            "Epoch 92, Training Loss: 0.2333, Validation Loss: 0.3284, Validation Accuracy: 0.8855\n",
            "Epoch 93, Training Loss: 0.2340, Validation Loss: 0.3289, Validation Accuracy: 0.8851\n",
            "Epoch 94, Training Loss: 0.2290, Validation Loss: 0.3281, Validation Accuracy: 0.8862\n",
            "Epoch 95, Training Loss: 0.2262, Validation Loss: 0.3242, Validation Accuracy: 0.8867\n",
            "Epoch 96, Training Loss: 0.2328, Validation Loss: 0.3352, Validation Accuracy: 0.8822\n",
            "Epoch 97, Training Loss: 0.2420, Validation Loss: 0.3469, Validation Accuracy: 0.8784\n",
            "Epoch 98, Training Loss: 0.2242, Validation Loss: 0.3288, Validation Accuracy: 0.8843\n",
            "Epoch 99, Training Loss: 0.2268, Validation Loss: 0.3289, Validation Accuracy: 0.8851\n",
            "Epoch 100, Training Loss: 0.2248, Validation Loss: 0.3300, Validation Accuracy: 0.8861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(nn.history)\n",
        "plt.plot(nn.history['train_loss'], label='Training loss')\n",
        "plt.plot(nn.history['val_loss'], label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "yChPrSn0MGDK",
        "outputId": "09483ec9-6092-4f83-9c6b-2459b389d972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_loss': [2.2995478582554223, 2.087394567150613, 1.214493654036126, 1.0090265428084353, 0.867794963020789, 0.8155946656448225, 0.7647632697768476, 0.7274362901630219, 0.6707184733623751, 0.6238823619895427, 0.6005689905118994, 0.5660281671481775, 0.556773259691518, 0.5407705021963517, 0.5398257185012457, 0.5129463564834227, 0.5143488249778014, 0.49364380192814694, 0.4823608885454465, 0.47448078407977445, 0.4710114342420121, 0.49147923218836725, 0.44855238572051714, 0.44656214871280675, 0.4440868438563864, 0.43206777879813396, 0.4198057170519255, 0.4242666696211396, 0.41148914027650507, 0.405459103958526, 0.4034612981603031, 0.3990988889836083, 0.39467874380596374, 0.38421156744574836, 0.3876289152968937, 0.3726945170476154, 0.3704313934221133, 0.3697011487521757, 0.3608868136900419, 0.3708431187454488, 0.3516289977866355, 0.3471122981449149, 0.3600589615872004, 0.3465224464052356, 0.35031131202454313, 0.3358453886909388, 0.3362838842118181, 0.33313579301552076, 0.32281956055845745, 0.34163017072677454, 0.31803845384038815, 0.3221747730967063, 0.3218308220452488, 0.31880301657424304, 0.3128218509238323, 0.3108479455867756, 0.32118679085836255, 0.29793366782064173, 0.3095271362337179, 0.3026727837187432, 0.29946491743614845, 0.28836101109903833, 0.3018978881839614, 0.2865214949168605, 0.318943149420743, 0.29761631317885623, 0.2934521607780634, 0.2774066264542497, 0.28101844210818555, 0.2742500606985353, 0.2912264417901331, 0.2853745707139224, 0.27118387597304733, 0.2786619947043758, 0.28113109542141135, 0.2621946446988158, 0.26466665511372295, 0.264435401260895, 0.25763145001066373, 0.25149525306598436, 0.25805989974185145, 0.25848485976984414, 0.2473618494240697, 0.24664902451538326, 0.2458370010870717, 0.2527172254600253, 0.24636620978939536, 0.2617186520486827, 0.2371213475878587, 0.25737688158010313, 0.23979507302878741, 0.2332753037965584, 0.23403758974945518, 0.22900371793863994, 0.22621265345366237, 0.23282841711852215, 0.24203253030490218, 0.22418829748917105, 0.22678842202842892, 0.22476920225037836], 'val_loss': [2.2996004075716003, 2.0851644433031535, 1.2089096096042484, 0.998227530012945, 0.8619672450086732, 0.8102387152326782, 0.7576929336190878, 0.7247395498900293, 0.6707528640736661, 0.6215879910094931, 0.6035517334026903, 0.5750415325243317, 0.5689259722064235, 0.5537628565670856, 0.549311775537476, 0.5271936441528309, 0.5323839478434573, 0.5071261033800182, 0.4985627694746431, 0.4892656775968052, 0.48891939962397535, 0.5141732591281281, 0.46793117749656477, 0.4646106155469667, 0.46331897163248714, 0.4532620917139172, 0.4401335895033053, 0.44284564605290516, 0.4332397181142974, 0.4286861379255861, 0.42650582047573216, 0.42425525228053423, 0.4186624613344402, 0.41127542534681866, 0.41361307613012754, 0.40090651534297195, 0.39708125051368126, 0.3997733307320088, 0.39113900588845224, 0.4015808033576202, 0.38331303239157644, 0.3806088674263679, 0.3952274635298574, 0.38190003191214084, 0.38609246176938766, 0.3722304311163516, 0.37392239619762846, 0.37373816277106137, 0.3614594835309135, 0.38244533004339426, 0.35903804229173153, 0.3652705626078323, 0.363857646976214, 0.362689417982172, 0.3608242267500738, 0.35907477172669544, 0.3715687969131811, 0.3477367525853172, 0.3598153866279914, 0.3533877049010223, 0.35451952378759016, 0.34429206474460444, 0.3603471267738957, 0.34185222970980855, 0.3782662747799016, 0.3569636505351815, 0.35486519816605416, 0.33868847756749376, 0.34251736900308555, 0.34108697407987876, 0.36143828533007205, 0.35467261996263405, 0.34239852205300536, 0.3469757233172062, 0.3523522496312468, 0.33344903248768665, 0.33905108901539444, 0.3387230778449862, 0.33379721501674775, 0.3290040962510257, 0.3382728015345227, 0.3415026119140545, 0.3298520813990386, 0.33013853416407113, 0.3292331421201266, 0.33954048324265756, 0.33551134962922907, 0.34911854079330934, 0.3291734749905576, 0.34859063662560524, 0.33011853923820994, 0.3283502313062902, 0.3288860950878117, 0.32807027232931424, 0.3241761706125953, 0.3351591813610879, 0.34691012694664497, 0.3287667244090607, 0.3289196785090208, 0.33001944315863], 'train_acc': [0.19877083333333334, 0.2386875, 0.52575, 0.6026458333333333, 0.6802916666666666, 0.6786041666666667, 0.7280625, 0.7481458333333333, 0.7685, 0.775875, 0.7861666666666667, 0.805, 0.8057291666666667, 0.8111875, 0.8085416666666667, 0.8207083333333334, 0.8204791666666666, 0.82725, 0.8307708333333333, 0.8333541666666666, 0.8335208333333334, 0.8225416666666666, 0.8435625, 0.8426666666666667, 0.8414166666666667, 0.8470625, 0.85225, 0.85025, 0.8558333333333333, 0.8562916666666667, 0.8570416666666667, 0.859875, 0.8596458333333333, 0.86525, 0.8645, 0.8692291666666667, 0.8689791666666666, 0.8674166666666666, 0.8731041666666667, 0.8685833333333334, 0.8753125, 0.8771041666666667, 0.870375, 0.8772916666666667, 0.8752291666666666, 0.8805416666666667, 0.8793333333333333, 0.8809166666666667, 0.88475, 0.8754375, 0.8866666666666667, 0.8835, 0.8844583333333333, 0.8841458333333333, 0.8871041666666667, 0.8880208333333334, 0.8836666666666667, 0.8930208333333334, 0.8869375, 0.8911875, 0.892125, 0.8964583333333334, 0.8909791666666667, 0.8974791666666667, 0.8859375, 0.8915833333333333, 0.8929375, 0.8999583333333333, 0.8971666666666667, 0.9017291666666667, 0.8923541666666667, 0.8974375, 0.9026666666666666, 0.9007708333333333, 0.898125, 0.9057291666666667, 0.9045416666666667, 0.9050833333333334, 0.9074166666666666, 0.9106041666666667, 0.908, 0.9064583333333334, 0.9117708333333333, 0.911875, 0.9119583333333333, 0.907625, 0.9114791666666666, 0.9058333333333334, 0.9150833333333334, 0.90475, 0.9134375, 0.9152291666666666, 0.915625, 0.9176875, 0.9197291666666667, 0.9160625, 0.9121875, 0.91875, 0.9198333333333333, 0.9197291666666667], 'val_acc': [0.19008333333333333, 0.23841666666666667, 0.5294166666666666, 0.6085, 0.68775, 0.68025, 0.733, 0.74725, 0.7651666666666667, 0.7761666666666667, 0.7900833333333334, 0.7995833333333333, 0.79675, 0.8013333333333333, 0.8076666666666666, 0.8125833333333333, 0.8159166666666666, 0.8208333333333333, 0.8249166666666666, 0.8273333333333334, 0.8250833333333333, 0.8084166666666667, 0.8375833333333333, 0.83725, 0.8335833333333333, 0.83725, 0.845, 0.8430833333333333, 0.8478333333333333, 0.8479166666666667, 0.85125, 0.8519166666666667, 0.8545, 0.85875, 0.8534166666666667, 0.8609166666666667, 0.8578333333333333, 0.8579166666666667, 0.8620833333333333, 0.8584166666666667, 0.864, 0.8656666666666667, 0.8625833333333334, 0.86625, 0.86625, 0.8716666666666667, 0.8675, 0.86825, 0.87425, 0.8660833333333333, 0.8744166666666666, 0.8723333333333333, 0.8710833333333333, 0.87, 0.8731666666666666, 0.8745, 0.8698333333333333, 0.87775, 0.874, 0.87675, 0.876, 0.878, 0.8751666666666666, 0.87925, 0.869, 0.8733333333333333, 0.8760833333333333, 0.8813333333333333, 0.8789166666666667, 0.8795, 0.8718333333333333, 0.8775, 0.8801666666666667, 0.8793333333333333, 0.8765, 0.8835, 0.8805, 0.8818333333333334, 0.882, 0.8845, 0.8815833333333334, 0.8801666666666667, 0.8838333333333334, 0.88325, 0.88375, 0.8790833333333333, 0.8815, 0.87925, 0.8840833333333333, 0.8781666666666667, 0.884, 0.8855, 0.8850833333333333, 0.88625, 0.8866666666666667, 0.8821666666666667, 0.8784166666666666, 0.8843333333333333, 0.8850833333333333, 0.8860833333333333]}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(nn.history['train_acc'], label='Training acc')\n",
        "plt.plot(nn.history['val_acc'], label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "LM0NHycjMNsV",
        "outputId": "35459de2-5293-4031-90fe-a2ed89634867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fby5-GvDQgAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final integration in progress\n",
        "points yet to be addressed-\n",
        "1. review the data downloading, loading, pre-processing to conclude on implementation fully-inline with assignment text.\n",
        "2. adding of data to this page in sections OR to other pages - highlighting the experiments we did wrt model architecture, and the observations/outcomes.\n",
        "3. Question 3.c - experiment with different weight initialization methods (random, Xavier, He)\n",
        "4. Report preparation -\n",
        "* explain the trials/experiments clearly.\n",
        "* explain the architecture of the models, learning rate, epochs used for training, evaluation metrics and the instructions for running the models.\n",
        "* add comparison of the performance of the models on the different hyperparameters you tried and justify the observed behavior.\n",
        "* share the references"
      ],
      "metadata": {
        "id": "mU-x5juTOSHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "\n",
        "# for MLP\n",
        "import numpy as np\n",
        "\n",
        "# for Pytorch based backbone CNN\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# PyTorch based flow to prepare and train a backbone CNN\n",
        "########################################################\n",
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Split the training data into Training and Validation datasets\n",
        "training_data_subset_size = int(0.8 * len(training_data))\n",
        "validate_data_subset_size = len(training_data) - training_data_subset_size\n",
        "training_data_subset, validation_data_subset = random_split(training_data, [training_data_subset_size, validate_data_subset_size])\n",
        "\n",
        "print(f'Complete Training Data: {training_data.size}')\n",
        "\n",
        "# define batch-size to load data\n",
        "batch_size = 64\n",
        "# define num of epochs to be run for training\n",
        "epochs = 10\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data_subset, batch_size=batch_size)\n",
        "validate_dataloader = DataLoader(validation_data_subset, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "# for X, y in test_dataloader:\n",
        "#     print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "#     print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "#     break\n",
        "\n",
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "##################################################\n",
        "# Define backbone CNN model for feature extraction\n",
        "##################################################\n",
        "class BackboneNeuralNetwork(nn.Module):\n",
        "    def __init__(self, backbone_only=False):\n",
        "        super().__init__()\n",
        "        # this property helps the CNN transition from a full-fledged network to a backbone CNN\n",
        "        # the default value is False - meaning an object of this class can be used to predict the labels for Fashion-MNIST dataset\n",
        "        # if the value is set to True - an object of this class will return the flattened output from conv layers - thus acting as a backbone\n",
        "        self.backbone_only = backbone_only\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.convolutional_relu_stack = nn.Sequential(\n",
        "            # Build a small CNN model consisting of 5 convolution layers.\n",
        "            # Each convolution layer would be followed by a ReLU activation and a max pooling layer\n",
        "            #\n",
        "            # ref - https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
        "            # nn.Sequential()\n",
        "            #\n",
        "            # ref - https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
        "            # nn.Conv2d(\n",
        "            #     in_channels = number of layers in input images. Grayscale or monochrome images have 1 in_channels\n",
        "            #     out_channels = number of channels in the output produced. This is a hyperparameter, which signifies the number of kernels\n",
        "            #     kernel_size = `(m,n)` for a kernel/filter dimension, or simply n for a square (n,n) kernel/filter dimension\n",
        "            #     stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None are other properties with default values\n",
        "            # )\n",
        "            #\n",
        "            # ref - https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU\n",
        "            # nn.ReLU()\n",
        "            #\n",
        "            # ref - https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d\n",
        "            # nn.MaxPool2d(\n",
        "            #     kernel_size = `(m,n)` for a kernel/filter dimension, or simply n for a square (n,n) kernel/filter dimension\n",
        "            #     stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False are other properties with default values\n",
        "            # )\n",
        "            nn.Conv2d(1, 49, (3, 3), stride=(1, 1), padding=(1, 1)),    # input = (1,28,28), output = ()\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),                                       # input = (), output = ()\n",
        "            nn.Conv2d(49, 98, (2, 2), stride=(1, 1), padding=(1,1)),    # input = (), output = ()\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),                                       # input = (), output = ()\n",
        "            nn.Conv2d(98, 196, (2, 2), stride=(1, 1), padding=(1,1)),   # input = (), output = ()\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),                                       # input = (), output = ()\n",
        "            nn.Conv2d(196, 392, (2, 2), stride=(1, 1), padding=(1, 1)), # input = (), output = ()\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),                                       # input = (), output = ()\n",
        "            nn.Conv2d(392, 784, (2, 2), stride=(1, 1), padding=(1, 1)), # input = (), output = ()\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2))                                        # input = (), output = (784,1,1)\n",
        "        )\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            #\n",
        "            # After extracting feature from CNN model use MLP for classification\n",
        "            #\n",
        "            # ref - https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
        "            # nn.Linear(\n",
        "            #     in_features = size of each input sample\n",
        "            #     out_features = size of each output sample\n",
        "            #     bias=True, device=None, dtype=None are other properties with default values\n",
        "            # )\n",
        "            #\n",
        "            # ref - https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax\n",
        "            # nn.Softmax()\n",
        "            #\n",
        "            nn.Linear(784, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.convolutional_relu_stack(x)\n",
        "        x2 = self.flatten(x1)\n",
        "        if self.backbone_only:  # return the flattened tensor containing feature extraction data\n",
        "            return x2\n",
        "        # default behaviour is to return the predicted labels\n",
        "        x3 = self.linear_relu_stack(x2)\n",
        "        return x3\n",
        "##################################################\n",
        "\n",
        "# create model instance\n",
        "model = BackboneNeuralNetwork().to(device)\n",
        "# print(model)\n",
        "\n",
        "# define loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "\n",
        "# forward pass implementation\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "# validation implementation\n",
        "def validate(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    validation_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            validation_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    validation_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Validation Phase: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {validation_loss:>8f} \\n\")\n",
        "\n",
        "# testing implementation\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Phase: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "# Train and Validate the CNN\n",
        "print(\"Training the backbone CNN model\")\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    validate(validate_dataloader, model, loss_fn)\n",
        "print(\"Done!\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch CNN backbone model state to model.pth\")\n",
        "\n",
        "# Load the model to perform testing on the trained variables\n",
        "model = BackboneNeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "# Test with the model\n",
        "test(test_dataloader, model, loss_fn)\n",
        "\n",
        "#####################################\n",
        "# Once the backbone model is prepared, trained, and tested,\n",
        "# start the integration of backbone model with custom MLP\n",
        "\n",
        "#####################################\n",
        "# Define MLP model for classification\n",
        "#####################################\n",
        "# Define a class to represent dense layer\n",
        "class DenseLayer:\n",
        "    def __init__(self, input_dim, output_dim, activation, lambda_reg=0.1, reg_type=None):\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.weights = np.random.randn(input_dim, output_dim)* 0.01\n",
        "        self.biases =  np.zeros((1, output_dim))\n",
        "        self.activation_name =activation\n",
        "        self.lambda_reg = lambda_reg\n",
        "        self.output = None\n",
        "        self.input = None\n",
        "        self.reg_type = reg_type\n",
        "\n",
        "        if activation == 'relu':\n",
        "            self.activation = self.relu\n",
        "            self.activation_prime = self.relu_prime\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = self.sigmoid\n",
        "            self.activation_prime = self.sigmoid_prime\n",
        "        elif activation == 'softmax':\n",
        "            self.activation = self.softmax\n",
        "            self.activation_prime = self.softmax_prime\n",
        "        else:\n",
        "            raise ValueError('activation function is not defined')\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"\"\"DenseLayer(input_dim:{self.input_dim}, output_dim:{self.output_dim}, activation:{self.activation_name})\"\"\"\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        self.input = input_data\n",
        "        #print(f\"self.input: {self.input.shape} \\n self.weights {self.weights.shape}\")\n",
        "        Z = np.dot(self.input, self.weights) + self.biases\n",
        "        #print(\"Z \", Z.shape)\n",
        "        self.output = self.activation(Z)\n",
        "        #print(f\"set..... self.output {self.output.shape}\")\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, dA, learning_rate, y=None):\n",
        "        \"\"\"Backward propagate through this layer.\n",
        "        dA is the derivative of the loss with respect to the output of this layer.\n",
        "        y is the true labels, which is only needed if this is an output layer with softmax activation.\n",
        "        \"\"\"\n",
        "        #print(f\"self.output {self.output.shape}\")\n",
        "        if self.activation_name == 'softmax':\n",
        "            y_one_hot = np.zeros_like(self.output)\n",
        "            y_one_hot[np.arange(len(y)), y] = 1\n",
        "            # Calculate the derivative of the loss with respect to the softmax inputs\n",
        "            dZ = (self.output - y_one_hot) / len(y)\n",
        "        else:\n",
        "            dZ = dA * self.activation_prime(self.output)\n",
        "\n",
        "        dA_prev = np.dot(dZ, self.weights.T)\n",
        "        dW = np.dot(self.input.T, dZ)\n",
        "        db = np.sum(dZ, axis=0, keepdims=True)\n",
        "\n",
        "        if self.reg_type:\n",
        "            if self.reg_type.upper() == \"L1\":\n",
        "                 #print(\"Using L1 regularization..\")\n",
        "                 weights_reg = self.lambda_reg * np.sign(self.weights)\n",
        "                 biases_reg = self.lambda_reg * np.sign(self.biases)\n",
        "            else:\n",
        "                 #print(\"Using L2 regularization....\")\n",
        "                 weights_reg = self.lambda_reg * self.weights\n",
        "                 biases_reg = self.lambda_reg * self.biases\n",
        "            self.weights -= learning_rate * (dW + weights_reg)\n",
        "            self.biases -= learning_rate * (db + biases_reg)\n",
        "        else:\n",
        "            #print(\"No regularization....\")\n",
        "            self.weights -= learning_rate * dW\n",
        "            self.biases -= learning_rate * db\n",
        "\n",
        "        return dA_prev\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def relu_prime(self, x):\n",
        "        return np.where(x > 0, 1, 0)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_prime(self, x):\n",
        "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
        "\n",
        "    # Ref https://stackoverflow.com/questions/40575841/numpy-calculate-the-derivative-of-the-softmax-function\n",
        "    def softmax(self,Z):\n",
        "        exp_scores = np.exp(Z)\n",
        "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)  # Softmax activation\n",
        "\n",
        "    # The derivative of the cross-entropy loss with respect to the input to the softmax is simply predictions - true_labels\n",
        "    def softmax_prime(self,x):\n",
        "        return 1\n",
        "\n",
        "# Define a class to represent MLP\n",
        "class MLP:\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.history = {'train_loss': [], 'val_loss': [], 'train_acc':[], 'val_acc':[]}\n",
        "\n",
        "    def add_layer(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for layer in self.layers:\n",
        "            X = layer.forward(X)\n",
        "        return X\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward(X)\n",
        "        return np.argmax(output, axis=1)\n",
        "\n",
        "    def cross_entropy_loss(self,y, output):\n",
        "        m = y.shape[0]\n",
        "        log_likelihood = -np.log(output[range(m), y] + 1e-9)\n",
        "        loss = np.sum(log_likelihood) / m\n",
        "        return loss\n",
        "\n",
        "    def train(self, train_data, train_labels, val_data, val_labels, epochs=10, batch_size=64, learning_rate=0.01):\n",
        "        for epoch in range(epochs):\n",
        "            permutation = np.random.permutation(train_data.shape[0])\n",
        "            train_data = train_data[permutation]\n",
        "            train_labels = train_labels[permutation]\n",
        "            for i in range(0, train_data.shape[0], batch_size):\n",
        "                X_batch = train_data[i:i+batch_size]\n",
        "                y_batch = train_labels[i:i+batch_size]\n",
        "                output = self.forward(X_batch)\n",
        "                self.backward(output, learning_rate, y_batch)\n",
        "            train_loss = self.cross_entropy_loss(train_labels, self.forward(train_data))\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "\n",
        "            val_output = self.forward(val_data)\n",
        "            val_loss = self.cross_entropy_loss(val_labels, val_output)  # Use val_labels directly\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "\n",
        "            val_accuracy = np.mean(self.predict(val_data) == val_labels)\n",
        "            train_acc = np.mean(self.predict(train_data) == train_labels)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_acc'].append(val_accuracy)\n",
        "            print(f'Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    def backward(self,output, learning_rate, y_train_batch):\n",
        "        for layer in reversed(self.layers):\n",
        "            #print(layer)\n",
        "            output = layer.backward(output, learning_rate,y_train_batch)\n",
        "#####################################\n",
        "\n",
        "# define the MLP architecture\n",
        "input_size = 28 * 28\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "\n",
        "# create the instance of MLP\n",
        "mlp = MLP()\n",
        "mlp.add_layer(DenseLayer(input_size, hidden_size, 'relu'))      #reg_type=\"L2\" does not help\n",
        "mlp.add_layer(DenseLayer(hidden_size, output_size, 'softmax'))  #reg_type=\"L2\" does not help\n",
        "\n",
        "# train the MLP using features extracted from pre-trained backbone\n",
        "def feature_extraction(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    features = np.empty((size, 28*28), dtype=np.float64)\n",
        "    labels = np.empty((size), dtype=np.int64)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            features[(batch*batch_size):((batch+1)*batch_size)] = pred.numpy()  # extract the features in numpy arrays\n",
        "            labels[(batch*batch_size):((batch+1)*batch_size)] = y.numpy()       # extract the features in numpy arrays\n",
        "    return features, labels\n",
        "\n",
        "# create the instance of `backbone CNN model`\n",
        "backbone_model = BackboneNeuralNetwork(backbone_only=True).to(device)\n",
        "backbone_model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "# extract the features using backbone CNN\n",
        "classifier_train_data, classifier_train_labels = feature_extraction(train_dataloader, backbone_model)\n",
        "classifier_validation_data, classifier_validation_labels = feature_extraction(validate_dataloader, backbone_model)\n",
        "\n",
        "# let the MLP classify the data now based on feature-extracted dataset\n",
        "epochs = 1\n",
        "learning_rate = 0.01\n",
        "print(\"Training the classigication MLP model\")\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    mlp.train(classifier_train_data, classifier_train_labels, classifier_validation_data, classifier_validation_labels)\n"
      ],
      "metadata": {
        "id": "gGdnlycUMQf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66bb89c5-0ceb-49e3-d6a6-1e59f3943618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n",
            "Using cpu device\n",
            "BackboneNeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (convolutional_relu_stack): Sequential(\n",
            "    (0): Conv2d(1, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(49, 98, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(98, 196, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (9): Conv2d(196, 392, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU()\n",
            "    (11): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv2d(392, 784, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU()\n",
            "    (14): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.303604  [   64/48000]\n",
            "loss: 2.300775  [ 6464/48000]\n",
            "loss: 2.272357  [12864/48000]\n",
            "loss: 1.089699  [19264/48000]\n",
            "loss: 1.010909  [25664/48000]\n",
            "loss: 1.092219  [32064/48000]\n",
            "loss: 1.033981  [38464/48000]\n",
            "loss: 0.727941  [44864/48000]\n",
            "Validation Error: \n",
            " Accuracy: 75.3%, Avg loss: 0.664898 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.598592  [   64/48000]\n",
            "loss: 0.690534  [ 6464/48000]\n",
            "loss: 0.807484  [12864/48000]\n",
            "loss: 0.479508  [19264/48000]\n",
            "loss: 0.478524  [25664/48000]\n",
            "loss: 0.612157  [32064/48000]\n",
            "loss: 0.676072  [38464/48000]\n",
            "loss: 0.567085  [44864/48000]\n",
            "Validation Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.515933 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.461079  [   64/48000]\n",
            "loss: 0.514847  [ 6464/48000]\n",
            "loss: 0.660541  [12864/48000]\n",
            "loss: 0.374317  [19264/48000]\n",
            "loss: 0.373749  [25664/48000]\n",
            "loss: 0.485534  [32064/48000]\n",
            "loss: 0.595392  [38464/48000]\n",
            "loss: 0.481672  [44864/48000]\n",
            "Validation Error: \n",
            " Accuracy: 84.1%, Avg loss: 0.436042 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.370248  [   64/48000]\n",
            "loss: 0.447413  [ 6464/48000]\n",
            "loss: 0.561746  [12864/48000]\n",
            "loss: 0.310950  [19264/48000]\n",
            "loss: 0.340050  [25664/48000]\n",
            "loss: 0.412570  [32064/48000]\n",
            "loss: 0.492441  [38464/48000]\n",
            "loss: 0.428306  [44864/48000]\n",
            "Validation Error: \n",
            " Accuracy: 85.9%, Avg loss: 0.378650 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.276271  [   64/48000]\n",
            "loss: 0.398572  [ 6464/48000]\n",
            "loss: 0.457655  [12864/48000]\n",
            "loss: 0.254115  [19264/48000]\n",
            "loss: 0.312685  [25664/48000]\n",
            "loss: 0.355247  [32064/48000]\n",
            "loss: 0.452425  [38464/48000]\n",
            "loss: 0.367185  [44864/48000]\n",
            "Validation Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.341942 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.235848  [   64/48000]\n",
            "loss: 0.345755  [ 6464/48000]\n",
            "loss: 0.419907  [12864/48000]\n",
            "loss: 0.212941  [19264/48000]\n",
            "loss: 0.292574  [25664/48000]\n",
            "loss: 0.319056  [32064/48000]\n",
            "loss: 0.427981  [38464/48000]\n",
            "loss: 0.344872  [44864/48000]\n",
            "Validation Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.314396 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.194510  [   64/48000]\n",
            "loss: 0.319295  [ 6464/48000]\n",
            "loss: 0.411859  [12864/48000]\n",
            "loss: 0.179296  [19264/48000]\n",
            "loss: 0.270883  [25664/48000]\n",
            "loss: 0.303679  [32064/48000]\n",
            "loss: 0.418366  [38464/48000]\n",
            "loss: 0.335929  [44864/48000]\n",
            "Validation Error: \n",
            " Accuracy: 89.1%, Avg loss: 0.300876 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.165848  [   64/48000]\n",
            "loss: 0.304731  [ 6464/48000]\n",
            "loss: 0.383163  [12864/48000]\n",
            "loss: 0.152386  [19264/48000]\n",
            "loss: 0.266620  [25664/48000]\n",
            "loss: 0.283818  [32064/48000]\n",
            "loss: 0.394022  [38464/48000]\n",
            "loss: 0.313508  [44864/48000]\n",
            "Validation Error: \n",
            " Accuracy: 89.7%, Avg loss: 0.289141 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.159962  [   64/48000]\n",
            "loss: 0.292883  [ 6464/48000]\n",
            "loss: 0.361193  [12864/48000]\n",
            "loss: 0.147845  [19264/48000]\n",
            "loss: 0.251402  [25664/48000]\n",
            "loss: 0.243451  [32064/48000]\n",
            "loss: 0.349353  [38464/48000]\n",
            "loss: 0.276038  [44864/48000]\n",
            "Validation Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.282770 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.146605  [   64/48000]\n",
            "loss: 0.273968  [ 6464/48000]\n",
            "loss: 0.327210  [12864/48000]\n",
            "loss: 0.134129  [19264/48000]\n",
            "loss: 0.243250  [25664/48000]\n",
            "loss: 0.244195  [32064/48000]\n",
            "loss: 0.315453  [38464/48000]\n",
            "loss: 0.252430  [44864/48000]\n",
            "Validation Error: \n",
            " Accuracy: 90.1%, Avg loss: 0.277249 \n",
            "\n",
            "Done!\n",
            "Saved PyTorch Model State to model.pth\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.286850 \n",
            "\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 1, Training Loss: 0.5226, Validation Loss: 0.5372, Validation Accuracy: 0.8492\n",
            "Epoch 2, Training Loss: 0.3164, Validation Loss: 0.3451, Validation Accuracy: 0.8822\n",
            "Epoch 3, Training Loss: 0.2761, Validation Loss: 0.3098, Validation Accuracy: 0.8909\n",
            "Epoch 4, Training Loss: 0.2576, Validation Loss: 0.2964, Validation Accuracy: 0.8928\n",
            "Epoch 5, Training Loss: 0.2464, Validation Loss: 0.2871, Validation Accuracy: 0.8968\n",
            "Epoch 6, Training Loss: 0.2393, Validation Loss: 0.2822, Validation Accuracy: 0.8969\n",
            "Epoch 7, Training Loss: 0.2340, Validation Loss: 0.2783, Validation Accuracy: 0.9012\n",
            "Epoch 8, Training Loss: 0.2305, Validation Loss: 0.2754, Validation Accuracy: 0.9018\n",
            "Epoch 9, Training Loss: 0.2283, Validation Loss: 0.2744, Validation Accuracy: 0.9016\n",
            "Epoch 10, Training Loss: 0.2256, Validation Loss: 0.2723, Validation Accuracy: 0.9038\n"
          ]
        }
      ]
    }
  ]
}